\chapter{Der SYCL-Standard}\label{sycl}

Die vor einigen Jahren veröffentlichte SYCL"=Spezifikation bietet eine neue
Möglichkeit, um ein Problem auf algorithmischer Ebene zu formulieren und dann
über die HLS in eine \gls{fpga}"=Schaltung zu synthetisieren. Eine einfache
SYCL"=Einführung sowie die für \gls{fpga}s wichtigen Besonderheiten sind daher
das Thema dieses Kapitels.

\section{Überblick}\label{sycl:ueberblick}

Mit dem SYCL"=Standard\footnote{Entgegen des optischen Anscheins ist
\glqq SYCL\grqq\ kein Akronym, sondern ein Eigenname.} verfolgt die
herausgebende Khronos"=Gruppe das Ziel eines abstrakten C++"=Programmiermodells
für \gls{opencl}, das die Modernität, Flexibilität und Einfachheit moderner
C++"=Standards bieten soll, während gleichzeitig die Konzeption und Portabilität
des \gls{opencl}"=1.2"=Standards beibehalten wird.
\cite[vgl.][15]{sycl2019}

Von \gls{opencl} erbt SYCL damit den Anspruch, ein einheitliche
Programmierschnittstelle für verschiedene Beschleunigertypen unterschiedlicher
Hersteller zu bieten. Das heißt, dass ein einmal geschriebener Quelltext, der
auf einem Beschleuniger ausgeführt werden soll, möglichst ohne große Änderungen
sowohl auf einer \gls{cpu}, einer \gls{gpu}, einem \gls{dsp} oder einem
\gls{fpga} ausführbar sein soll.

SYCL unterscheidet sich von \gls{opencl} im Hinblick auf die Struktur des
Quelltextes: bei \gls{opencl} sind die Quelltexte für das steuernde Programm
(\textit{Host}) und den Programmteil, der vom Beschleuniger (\textit{Device})
ausgeführt wird, voneinander getrennt. Diese Design"=Entscheidung des
\gls{opencl}"=Standards ist durch das Ziel der Plattformunabhängigkeit
begründet: ein Entwickler kennt während der Kompilierung des Hauptprogramms
nicht notwendigerweise die vorhandenen Beschleuniger der Zielplattform. Dadurch
wird der \textit{Device}"=spezifische Quelltext häufig erst zur Laufzeit des
Programms kompiliert, da in diesem Moment der konkrete Beschleuniger bekannt
ist. Dieser Ansatz hat jedoch den Nachteil, dass der Compiler des
\textit{Device}"=Quelltexts (im Folgenden als \textit{Kernel} bezeichnet) keine
Annahmen mehr über das \textit{Host}"=Programm bzw. den den \textit{Kernel}
umgebenden Quelltext mehr treffen kann, was zu einem geringeren
Optimierungspotential führt. \gls{opencl}"=Kernel lassen sich zwar auch vor
der Laufzeit des Programms für eine konkrete Zielplattform kompilieren (dies
geschieht aufgrund der langen Kompilierungszeiten bei \gls{fpga}s), büßen
dadurch aber ihre Plattformunabhängigkeit ein.

Ein SYCL-Quelltext kennt dagegen keine strikte Trennung zwischen \textit{Host}-
und \textit{Device}"=Anweisungen. Neben der besseren Analyse des den
\textit{Kernel} umgebenden Kontexts hat dies den weiteren Vorteil, dass
\textit{Host} und \textit{Device} Quelltext teilen können, wie etwa den
beidseitig verwendeter Hilfsfunktionen. Der \textit{Kernel} wird dabei vom
\textit{Device}"=Compiler extrahiert und in eine Form umgewandelt, die von der
Ziel"=Hardware zur Laufzeit kompiliert oder ausgeführt werden kann.
\cite[vgl][35]{sycl2019}

Ein weiterer wichtiger Unterschied zu \gls{opencl} besteht darin, dass
jedes SYCL"=Programm mit einem Standard"=C++"=Compiler übersetzt werden kann,
sofern keine direkten Interaktionen mit \gls{opencl} selbst erfolgen. Damit
lässt sich ein SYCL"=Programm auf jeder \gls{cpu} ausführen, für die ein
(moderner) C++"=Compiler existiert, wenngleich dies Einschränkungen bei der
erreichbaren Leistung bedeuten kann. So schreibt die SYCL"=Spezifikation für
diesen Fall nur die Ausführbarkeit selbst vor, aber nicht die Nutzung aller
\gls{cpu}"=Kerne oder SIMD"=Register. \cite[vgl.][15]{sycl2019}

Seit der ersten Veröffentlichung im März 2014 \cite[vgl.][]{khronos2014} mit der
Versionsnummer 1.2 wurde die SYCL"=Spezifikation stetig weiterentwickelt; die
zur Zeit aktuelle Spezifikation vom April 2019 trägt die Revisionsnummer 1.2.1
Revision 5. \cite[vgl.][1]{sycl2019}

Teil der Khronos"=Gruppe sind (unter anderen) die \gls{fpga}"=Hersteller Xilinx
und Intel. Xilinx unterstützt den SYCL"=Standard in Form einer Erweiterung der
bestehenden HLS"=Werkzeuge bereits, während Intel dies für die eigenen FPGAs
mittelfristig plant; für Intel"=\gls{cpu}s und "=\gls{gpu}s ist bereits eine
SYCL"=Implementierung verfügbar (der Abschnitt~\ref{sycl:implementierungen}
befasst sich mit allen verfügbaren Implementierungen).

\subsection{AXPY und SYCL}\label{sycl:ueberblick:saxpy}

Ein im Bereich der Programmierung häufig verwendetes einführendes Beispiel
ist der sogenannte AXPY"=Algorithmus, der ursprünglich aus der BLAS"=Bibliothek
stammt. Dieser führt die Berechnung
\[\vec{y} = a \cdot \vec{x} + \vec{y}\]
aus und ist aufgrund seiner Einfachheit und hohen erreichbaren Parallelität
(sofern $\vec{x}$ und $\vec{y}$ viele Elemente enthalten) sehr beliebt.
\cite[vgl.][]{lawson1979}

AXPY lässt sich auch für eine Einführung in SYCL gut verwenden und wird daher in
den folgenden Abschnitten als illustrierendes Beispiel genutzt.

Ein SYCL"=Programm lässt sich in mehrere aufeinander aufbauende Stufen
unterteilen, wie in Quelltext~\ref{sycl:ueberblick:saxpy:struktur} zu sehen ist.
Die einzelnen Platzhalter im Quelltext werden in den nächsten Abschnitten mit
Inhalt gefüllt.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
#include <cstdlib>

#include <CL/sycl.hpp>

auto main() -> int
{
    // Beschleunigerwahl und Befehlswarteschlange

    // Speicherreservierung und -initialisierung

    // Kerneldefinition und -ausführung

    // Synchronisierung

    return EXIT_SUCCESS;
}
    \end{minted}
    \caption{Struktur eines SYCL-Programms}
    \label{sycl:ueberblick:saxpy:struktur}
\end{code}

\subsubsection{Beschleunigerwahl und Befehlswarteschlange}
\label{sycl:ueberblick:saxpy:queue}

Von \gls{opencl} erbt SYCL die Plattformunabhängigkeit. Es wird das
Vorhandensein mindestens einer \gls{opencl}"=Plattform auf dem System
angenommen\footnote{Aber nicht vorausgesetzt! Jede SYCL"=Implementierung muss
auch ohne eine OpenCL"=Plattform auf dem Host lauffähig sein.}, was im
Umkehrschluss bedeutet, dass unter Umständen zwischen mehreren verschiedenen
Plattformen konkurrierender Hersteller gewählt werden muss. 

Die SYCL"=Spezifikation bietet dem Programmierer mehrere Möglichkeiten, die
gewünschte Plattform für sein Programm auszuwählen. Der einfachste Ansatz
besteht darin, eine Befehlswarteschlange (die \texttt{queue} genannt wird) für
einen Beschleuniger zu konstruieren. Über die Befehlswarteschlange erfolgt die
Kommunikation zwischen dem \textit{Host} und einem \textit{Device}, also
Kopieroperationen, das Starten eines \textit{Kernels} sowie die
Synchronisierung. Letztere ist notwendig, da es sich bei dem \textit{Device}
um eine vom \textit{Host} weitestgehend unabhängige Hardware handelt, die
Operationen also (aus Sicht des \textit{Hosts}) asynchron ablaufen.

Jedes genutzte \textit{Device} erhält in SYCL mindestens eine eigene
\texttt{queue}, so dass auch die Nutzung mehrerer Beschleuniger möglich ist.

Eine \texttt{queue} kann durch das Übergeben eines Auswahlkriteriums für das
gewünschte \textit{Device} konstruiert werden. Die Auswahlkriterien werden in
der SYCL"=Spezifikation \texttt{device\_selector} genannt. Neben den in der
Spezifikation vorhandenen Kriterien (beispielsweise \texttt{cpu\_selector},
\texttt{gpu\_selector} oder \texttt{host\_selector}) ist es Herstellern oder dem
Programmierer selbst möglich, durch das Erben von der Elternklasse
\texttt{device\_selector} eigene Kriterien zu definieren. Beispielsweise findet
sich in den Testfällen der von Xilinx entwickelten SYCL"=Implementierung ein
\texttt{device\_selector} für die eigenen Geräte, der die \gls{fpga}s über den
Firmennamen findet. Mit dessen Hilfe lässt sich die Befehlswarteschlange für
einen Xilinx"=FPGA wie in Quelltext~\ref{sycl:ueberblick:saxpy:queue:src}
dargestellt erzeugen.
%
\begin{code}
    \begin{minted}[fontsize=\small]{c++}
class XOCLDeviceSelector : public cl::sycl::device_selector {
    public:
        int operator()(const cl::sycl::device &Device) const override {
            const std::string DeviceVendor =
                            Device.get_info<cl::sycl::info::device::vendor>();
            return (DeviceVendor.find("Xilinx") != std::string::npos) ? 1 : -1;
        }
};

/* ... */

auto queue = cl::sycl::queue{XOCLDeviceSelector{}};
    \end{minted}
    \caption{Auswahl eines Xilinx"=FPGAs und Erzeugung einer zugehörigen
             Befehlswarteschlange}
    \label{sycl:ueberblick:saxpy:queue:src}
\end{code}
%
\noindent
Programmierern, die mehr Kontrolle über die Initialisierung des Beschleunigers
oder der gesamten SYCL"=Laufzeitumgebung wünschen, stellt die
SYCL"=Spezifikation das aus \gls{opencl} bekannte Schema zur Verfügung. Der
Programmierer kann zunächst eine Liste aller zur Verfügung stehenden
\gls{opencl}"=Plattformen anfordern, aus denen er frei wählen kann. Auf dem
Fundament der gewählten Plattform erzeugt der Programmierer im nächsten Schritt
einen SYCL"=Kontext (der einen \gls{opencl}"=Kontext kapselt). Der Kontext
stellt wiederum eine Liste aller \textit{Devices} der Plattform bereit, aus der
ein oder mehrere Beschleuniger ausgesucht werden können. Die Auswahl dient dann
als Parameter für die Erzeugung einer SYCL"=Befehlswarteschlange. In jedem
der genannten Schritte stehen dem Programmierer zahlreiche Informationen über
die jeweilige Klasse zur Verfügung (Hersteller der Plattform oder des
Beschleunigers, Hardware"=Eigenschaften, verfügbare Erweiterungen, usw.), die
eine Verfeinerung der Auswahl erlauben.

Der Quelltext~\ref{sycl:ueberblick:saxpy:queue:ausfuehrlich} zeigt das
ausführliche Schema, in den folgenden Abschnitten wird jedoch die oben gezeigte,
einfachere und kürzere Variante verwendet.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto platforms = cl::sycl::platform::get_platforms();
auto my_platform = /* ... */;

auto context = cl::sycl::context{my_platform};

auto devices = context.get_devices();
auto my_device = /* ... */;

auto queue = cl::sycl::queue{my_device};
    \end{minted}
    \caption{Ausführliche Beschleunigerwahl und Befehlswarteschlangen"=Konstruktion}
    \label{sycl:ueberblick:saxpy:queue:ausfuehrlich}
\end{code}

\subsubsection{Speicherreservierung und -initialisierung}
\label{sycl:ueberblick:saxpy:buffer}

Für die Vektoren $\vec{x}$ und $\vec{y}$ ist eine Speicherreservierung auf dem
\textit{Device} sowie die Initialisierung des reservierten Speichers notwendig
(die Konstante $a$ kann als einfacher Parameter übergeben werden). SYCL stellt
dafür zwei Klassen bereit:
%
\begin{itemize}
    \item Ein \texttt{buffer} kapselt die auf dem \textit{Device} reservierten
          Speicherbereiche. Dabei ist zu beachten, dass ein \texttt{buffer}
          keinem \textit{Device} direkt zugeordnet ist, sondern dem gesamten
          Kontext zur Verfügung steht. Ein \texttt{buffer} kann so auch auf
          mehreren \textit{Devices} verwendet werden, die notwendige
          Synchronisierung wird von der SYCL"=Laufzeitumgebung vorgenommen.
    \item Ein \texttt{accessor} sorgt für den Zugriff auf den von einem
          \texttt{buffer} verwalteten Speicher. Es existieren verschiedene
          \texttt{accessor}"=Typen, darunter auch einer für den Speicherzugriff
          auf der \textit{Host}"=Seite. Mit diesem lässt sich ein
          \texttt{buffer} direkt initialisieren, ohne eine explizite Kopie
          anstoßen zu müssen. Aus Sicht des Programmierers lässt sich ein
          \texttt{accessor} wie ein Zeiger oder Feld verwenden, d.h. über den
          \texttt{[]}"=Operator.
\end{itemize}
%
\noindent
Ein \texttt{buffer} besteht aus einer endlichen Anzahl von Elementen desselben
Typs und kann ein-, zwei- oder dreidimensional sein. Der Elemente-Typ sowie die
Dimension des Puffers sind als Template"=Parameter zur Compile"=Zeit anzugeben,
während die Anzahl als Laufzeit"=Parameter übergeben wird. Ein \texttt{accessor}
lässt sich über die Methode \texttt{get\_access} der \texttt{buffer}"=Klasse
erzeugen. Dabei wird als Template"=Parameter der gewünschte Zugriffstyp
angegeben. Diese Information wird von der SYCL"=Laufzeitumgebung zur Sortierung
der Abhängigkeiten zwischen Operationen auf dem \textit{Device} genutzt (siehe
auch Abschnitt~\ref{sycl:konzepte:abhaengigkeiten}).

SYCL unterscheidet sechs verschiedene Zugriffstypen:
\begin{itemize}
    \item \texttt{read} gestattet ausschließlich lesenden Zugriff auf den
          Puffer.
    \item \texttt{write} ermöglicht ausschließlich schreibenden Zugriff.
    \item Durch \texttt{read\_write} kann sowohl lesend als auch schreibend
          auf den \texttt{buffer} zugegriffen werden.
    \item \texttt{discard\_write} ermöglicht ausschließlich schreibenden Zugriff
          und verwirft alle vorher im Puffer enthaltenen Elemente (also auch bei
          partiellem Zugriff).
    \item \texttt{discard\_read\_write} ist die Kombination aus
          \texttt{read\_write} und \texttt{discard\_write}.
    \item \texttt{atomic} ermöglicht atomaren Zugriff bei paralleler Nutzung des
          Puffers.
\end{itemize}

Für das AXPY"=Beispiel lassen sich die benötigten Felder wie in
Quelltext~\ref{sycl:ueberblick:saxpy:buffer:src} dargestellt anlegen und
initialisieren.
%
\begin{code}
    \begin{minted}[fontsize=\small]{c++}
// Puffer enthalten 1024 Elemente
const auto buf_range = cl::sycl::range<1>{1024};

// erzeuge eindimensionale Puffer für int-Elemente
auto buf_x = cl::sycl::buffer<int, 1>{buf_range};
auto buf_y = cl::sycl::buffer<int, 1>{buf_range};

// greife auf x und y zu, verwirf vorherige Elemente
auto h_acc_x = buf_x.get_access<cl::sycl::access::mode::discard_write>();
auto h_acc_y = buf_x.get_access<cl::sycl::access::mode::discard_write>();

// initialisiere x und y
for(auto i = 0; i < 1024; ++i)
{
    h_acc_x[i] = /* ... */;
    h_acc_y[i] = /* ... */;
}
    \end{minted}
    \caption{Speicherreservierung und -initialisierung in SYCL}
    \label{sycl:ueberblick:saxpy:buffer:src}
\end{code}

\subsubsection{Kerneldefinition und -ausführung}
\label{sycl:ueberblick:saxpy:kernel}

Im nächsten Schritt wird der eigentliche Kernel definiert und ausgeführt. Ein
SYCL"=Kernel besteht aus zwei Teilen: der eigentlichen Kernel"=Funktion, also
der Abbildung des Algorithmus auf SYCL"=C++"=Quelltext, sowie den Abhängigkeiten
(in Form von \texttt{accessor}"=Variablen). Kernel"=Funktion und Abhängigkeiten
bilden gemeinsam eine \textit{command group} und werden in dieser Form an die
\texttt{queue} zur Ausführung übergeben. Dabei kann jede \textit{command group}
nur genau eine Kernel"=Funktion (oder explizite Kopieroperation) enthalten. Es
bildet sich damit für das AXPY"=Beispiel das in
Quelltext~\ref{sycl:ueberblick:saxpy:kernel:cg} gezeigte Grundgerüst einer
\textit{command group}, welche in diesem Fall als C++"=Lambdafunktion notiert
wird.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
[&](cl::sycl::handler& cgh)
{
    auto d_acc_x = buf_x.get_access<cl::sycl::access::mode::read>(cgh);
    auto d_acc_y = buf_y.get_access<cl::sycl::access::mode::read_write>(cgh);

    // Kernel-Funktionsaufruf
}
    \end{minted}
    \caption{Struktur einer \textit{command group}}
    \label{sycl:ueberblick:saxpy:kernel:cg}
\end{code}

SYCL bietet für verschiedene Anwendungsfälle unterschiedliche Methoden für den
Aufruf der Kernel"=Funktion. Für datenparallele Algorithmen bietet sich vor
allem der Aufruf über \texttt{parallel\_for} an. Dieser entspricht dem aus
\gls{opencl} bekannten \textit{NDRange}"=Kernel und nutzt die
SIMD"=Eigenschaften der zur Verfügung stehenden Beschleuniger. Auf CPUs können
so durch einen Aufruf mehrere Kerne und deren SIMD"=Register genutzt werden oder
auf einer GPU die Multiprozessoren und SIMD"=Einheiten. Auf einem FPGA kann
durch \texttt{parallel\_for} ebenfalls eine SIMD"=Schaltung synthetisiert
werden. 

Für aufgabenparallele Algorithmen steht in SYCL der Aufruf \texttt{single\_task}
zur Verfügung, was einem \textit{Task}"=Kernel in \gls{opencl} entspricht.
Dieser wird z.B. auf einer CPU nur auf einem einzelnen Kern ausgeführt. Mehrere
Kernel dieses Typs lassen sich dann parallel auf den vorhandenen Kernen
ausführen.

Für das AXPY"=Beispiel bietet sich der datenparallele Fall an, weshalb die
Kernel"=Funktion wie in Quelltext~\ref{sycl:ueberblick:saxpy:kernel:call}
gezeigt aufgerufen wird. Die \num{1024} Elemente der Vektoren werden dabei als
Arbeitsgröße mit übergeben. Die SYCL"=Laufzeitumgebung generiert daraus einen
Ausführungsraum mit \num{1024} \textit{work-items}, einer Abstraktion der
zugrundeliegenden Hardware"=Features (SIMD"=Register, Threads, usw.). Der Index
des jeweiligen \textit{work-items} wird als Parameter an die Kernel"=Funktion
übergeben und kapselt einen Index, der für den Zugriff auf ein Element im
Speicher verwendet werden kann. 

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
[&](cl::sycl::handler& cgh)
{
    auto d_acc_x = buf_x.get_access<cl::sycl::access::mode::read>(cgh);
    auto d_acc_y = buf_y.get_access<cl::sycl::access::mode::read_write>(cgh);

    cgh.parallel_for<class axpy>(cl::sycl::range<1>{1024},
    [=](cl::sycl::item<1> work_item)
    {
        auto idx = work_item.get_id();
        d_acc_y[idx] = a * d_acc_x[idx] + d_acc_y[idx];
    });
}
    \end{minted}
    \caption{Struktur einer \textit{command group} mit Kernel"=Aufruf}
    \label{sycl:ueberblick:saxpy:kernel:call}
\end{code}

\subsubsection{Synchronisierung}
\label{sycl:ueberblick:saxpy:sync}

Nachdem der Kernel an die Befehlswarteschlange übergeben wurde, muss das
Ergebnis überprüft werden. Um darauf zugreifen zu können, ist zunächst die
Synchronisierung von \textit{Host} und \textit{Device} erforderlich, da beide
asynchron zueinander arbeiten. Die \texttt{queue} verfügt jedoch über die
Methode \texttt{wait}, die den \textit{Host} so lange warten lässt, bis alle bis
zu diesem Zeitpunkt eingereihten Befehle abgearbeitet wurden. Dies ist in
Quelltext~\ref{sycl:ueberblick:saxpy:sync:wait} dargestellt. Anschließend
lassen sich die Elemente des Vektors $\vec{y}$ auf der \textit{Host}"=Seite
über den während der Initialisierung der Puffer angelegten \texttt{accessor}
überprüfen.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
queue.wait();
    \end{minted}
    \caption{Struktur einer \textit{command group} mit Kernel"=Aufruf}
    \label{sycl:ueberblick:saxpy:sync:wait}
\end{code}

\subsubsection{Zusammenfassung}
\label{sycl:ueberblick:saxpy:zusammenfassung}

Das gesamte SYCL"=AXPY"=Beispiel findet sich in
Quelltext~\ref{sycl:ueberblick:saxpy:zusammenfassung:code}, einschließlich
einiger kleinerer, in den vorigen Abschnitten ausgelassener, Details.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
#include <cstdlib>
#include <CL/sycl.hpp>

class XOCLDeviceSelector : public cl::sycl::device_selector {
    public:
        int operator()(const cl::sycl::device &Device) const override {
            const std::string DeviceVendor =
                            Device.get_info<cl::sycl::info::device::vendor>();
            return (DeviceVendor.find("Xilinx") != std::string::npos) ? 1 : -1;
        }
};

auto main() -> int {
    constexpr auto a = 42;

    // Beschleunigerwahl und Befehlswarteschlange
    auto queue = cl::sycl::queue{XOCLDeviceSelector{}};

    // Speicherreservierung und -initialisierung
    const auto buf_range = cl::sycl::range<1>{1024};

    auto buf_x = cl::sycl::buffer<int, 1>{buf_range};
    auto buf_y = cl::sycl::buffer<int, 1>{buf_range};

    auto h_acc_x = buf_x.get_access<cl::sycl::access::mode::discard_write>();
    auto h_acc_y = buf_x.get_access<cl::sycl::access::mode::discard_write>();

    for(auto i = 0; i < 1024; ++i)
    {
        h_acc_x[i] = /* ... */;
        h_acc_y[i] = /* ... */;
    }

    // Kerneldefinition und -ausführung
    queue.submit([&](cl::sycl::handler& cgh)
    {
        auto d_acc_x = buf_x.get_access<cl::sycl::access::mode::read>(cgh);
        auto d_acc_y = buf_y.get_access<cl::sycl::access::mode::read_write>(cgh);

        cgh.parallel_for<class axpy>(cl::sycl::range<1>{1024},
        [=](cl::sycl::item<1> work_item)
        {
            auto idx = work_item.get_id();
            d_acc_y[idx] = a * d_acc_x[idx] + d_acc_y[idx];
        });
    });

    // Synchronisierung
    queue.wait();

    return EXIT_SUCCESS;
}
    \end{minted}
    \caption{AXPY -- vollständiges SYCL"=Beispiel}
    \label{sycl:ueberblick:saxpy:zusammenfassung:code}
\end{code}

\section{Weiterführende Konzepte}\label{sycl:konzepte}

\subsection{Hardware"=Abstraktion}

\subsection{Abhängigkeitsverwaltung}
\label{sycl:konzepte:abhaengigkeiten}

\subsection{Fehlerbehandlung}

\subsection{Profiling}

\subsection{Referenz-Semantik}

Ein wichtiger Unterschied zur üblichen C++"=Programmierung sind SYCLs
Referenz"=Semantiken. Die Spezifikation schreibt vor
\cite[siehe][Abschnitt 4.3.2]{sycl2019}:
\begin{otherlanguage}{english}
    \begin{quote}
        Each of the following SYCL runtime classes: \texttt{device},
        \texttt{context}, \texttt{queue}, \texttt{program}, \texttt{kernel},
        \texttt{event}, \texttt{buffer}, \texttt{image}, \texttt{sampler},
        \texttt{accessor} and \texttt{stream} must obey the following
        statements, where \texttt{T} is the runtime class: [...]
        \\
        Any instance of \texttt{T} that is constructed as a copy of another
        instance, via either the copy constructor or copy assignment operator,
        must behave as-if it were the original instance and as-if any action
        performed on it were also performed on the original instance and if said
        instance is not a host object must represent and continue to represent
        the same underlying OpenCL objects as the original instance where
        applicable.
    \end{quote}
\end{otherlanguage}
Bemerkenswert ist, dass diese Semantik ebenfalls für die Typen \texttt{buffer}
und \texttt{image} gilt, das heißt Datentypen, die größere Speicherbereiche
kapseln. In der C++-Standardbibliothek werden die internen Felder vergleichbarer
Typen (wie \texttt{vector}) ebenfalls kopiert. Nach dem Kopiervorgang existieren
damit zwei voneinander verschiedene Objekte, die getrennte Speicherbereiche
verwalten. Die SYCL-Objekte beziehen sich jedoch nach dem Kopiervorgang auf den
selben Speicherbereich, es wird also bei der Objektkopie kein neuer Speicher
angelegt. De facto handelt es sich bei der Kopie eines SYCL-Objekts daher
lediglich um eine Referenz auf das ursprüngliche Objekt.

\section{Implementierungen}\label{sycl:implementierungen}

Der ersten Veröffentlichung der SYCL-Spezifikation im Mai 2015 folgten im Laufe
der Zeit einige Implementierungen. Diese werden in den folgenden Abschnitten
vorgestellt.

Darüber hinaus existiert eine von der Firma Codeplay betreute Internet-Seite,
die sich dem gesamten \gls{sycl}"=Ökosystem widmet. \cite[vgl.][]{sycltech}

\subsection{ComputeCpp}

Die schottische Firma Codeplay ist der zur Zeit einzige Anbieter einer
kommerziellen SYCL-Implementierung, die unter dem Namen \textit{ComputeCpp}
vermarktet wird. Sie richtet sich in erster Linie an Hardware für die Bereiche
Automotive und Embedded, unterstützt jedoch (bei einer bereits vorhandenen
OpenCL"=Implementierung) auch \gls{cpu}s und \gls{gpu}s der Firma Intel sowie
(experimentell) NVIDIA-\gls{gpu}s. Nach vorheriger Registrierung ist für
nichtkommerzielle Zwecke auch eine kostenlose \textit{community edition}
verfügbar. \cite[vgl.][]{computecpp}

\subsection{Intel}

Eine wichtige quelloffene Implementierung kommt von der Firma Intel. Strategisch
soll diese Implementierung mit dem Compiler \textit{clang} des LLVM"=Projekts
vereinigt werden. Zur Zeit handelt es sich jedoch noch um eine eigenständige
Implementierung, die vor allem auf die Intel"=\gls{opencl}"=Implementierungen
für \gls{cpu}s und \gls{gpu}s abzielt. Aktivitäten innerhalb des öffentlich
einsehbaren Quelltext"=Repositoriums deuten jedoch darauf hin, dass auch die
eigenen \gls{fpga}s unterstützt werden sollen. \cite[vgl.][]{intelsycl}

\subsection{triSYCL}

Das Projekt triSYCL ist eine quelloffene Implementierung des
\gls{sycl}"=Standards, die früher von der Firma AMD und jetzt von Xilinx
entwickelt wird. Nach eigener Aussage dient es vornehmlich experimentellen
Zwecken, um dem \gls{sycl}"=Komitee und dem \gls{opencl}"=C++"=Komitee des
Khronos"=Konsortiums sowie dem C++"=Standardisierungskomitee der ISO Feedback
liefern zu können. Das Hauptprojekt unterstützt \gls{cpu}s (über \gls{openmp}
oder \gls{tbb}) sowie \gls{opencl}"=Implementierungen, die die Verarbeitung des
\gls{spir}"=Zwischencodes unterstützen. \cite[vgl.][]{trisycl}

Daneben existiert ein von der Intel"=Implementierung abgeleitetes
Compiler-Projekt, das sich vornehmlich der besseren Unterstützung von
Xilinx"=\gls{fpga}s anzunehmen scheint. \cite[vgl.][]{trisyclclang}

\subsection{hipSYCL}

Der Heidelberger Doktorand Aksel Alpay ist der Autor einer weiteren
SYCL-Implementierung. Diese setzt auf dem CUDA"=Klon der Firma AMD auf, der
\gls{gpgpu}"=Sprache \gls{hip}. \gls{hip} ist sowohl auf AMD- als auch auf
NVIDIA"=\gls{gpu}s ausführbar. Dadurch können auch mit hipSYCL entwickelte
Programme auf diesen \gls{gpu}s ausgeführt werden. hipSYCL war über weite
Strecken ein Ein-Mann-Projekt, erst seit Februar 2019 ist die regelmäßige
Mitarbeit eines weiteren Entwicklers zu verzeichnen. Aus diesem Grund ist
hipSYCL unvollständig implementiert, es fehlen unter anderem atomare Funktionen
oder die Möglichkeit, Ausnahmefehler zu werfen und abzufangen.
\cite[vgl.][]{hipsycl}

\subsection{sycl-gtx}

Eine weitere Open-Source-Implementierung ist das eingangs erwähnte
\textit{sycl"=gtx}. Ursprünglich ist diese Implementierung im Rahmen einer
Masterarbeit entstanden \cite[vgl.][]{zuzek2016} und wird bis heute vom
ursprünglichen Autoren weiterentwickelt. Aufgrund der begrenzten
Entwicklerkapazitäten ist diese Variante aber immer noch sehr rudimentär und
unterstützt nur eine Teilmenge der SYCL"=Spezifikation.

Im Gegensatz zu den anderen Implementierungen wird der SYCL"=\gls{kernel} erst
zur Laufzeit des kompilierten Programms in einen \gls{opencl}"=\gls{kernel}
umgewandelt und anschließend an die zugrundeliegende
\gls{opencl}"=Laufzeitumgebung weitergereicht. Dadurch ist \textit{sycl"=gtx}
sehr portabel, da es nicht auf eine bestimmte Hardware beschränkt ist;
grundsätzlich soll es mit jeder \gls{opencl}"=Umgebung kompatibel sein, die
mindestens den Standard in Version 1.2 unterstützt. 
\cite[vgl.][47\psqq]{zuzek2016}

\section{Erweiterungen für FPGAs}\label{sycl:erweiterungen}

Wie im vorherigen Abschnitt dargestellt wurde, stehen für die \gls{fpga}s der
großen Hersteller Intel und Xilinx bereits experimentelle
\gls{sycl}"=Implementierungen zur Verfügung. Um die speziellen Eigenschaften
dieses Hardware"=Typs besser nutzen zu können, gibt es in beiden
Implementierungen Erweiterungen, die \gls{sycl}s Umfang um
\gls{fpga}"=spezifische Funktionalität ergänzen.

\subsection{Intel-FPGAs}\label{sycl:erweiterungen:intel}

Die Firma Intel will mit ihrer SYCL-Implementierung wahrscheinlich mittel- bis
langfristig auch die eigenen \glspl{fpga} ansprechen. Um die Eigenheiten dieses
Hardware-Typs besser nutzen zu können, werden in der Header-Datei
\texttt{CL/sycl/intel/fpga\_extensions.hpp} bereits zwei FPGA-spezifische
Erweiterungen mitgeliefert, die in den nächsten Abschnitten kurz vorgestellt
werden.

\subsubsection{Beschleuniger-Auswahl}\label{sycl:erweiterungen:intel:selector}

SYCL bietet im Rahmen der Spezifikation nur \texttt{device\_selector}-Typen
für \gls{cpu}s und \gls{gpu}s an. Um einfach auf Intel-\gls{fpga}s zugreifen
zu können, gibt es die Erweiterung \texttt{fpga\_selector} innerhalb des
für Intel-Erweiterungen vorgesehenen Namensraums. Diese kann wie die in der
Spezifikation vorhandenen Varianten an den Konstruktor einer \texttt{queue}
übergeben werden (siehe Quelltext~\ref{sycl:erweiterungen:intel:selector:src}).

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto queue = cl::sycl::queue{cl::sycl::intel::fpga_selector{}};
    \end{minted}
    \caption{Auswahl eines Intel-FPGA}
    \label{sycl:erweiterungen:intel:selector:src}
\end{code}

\subsubsection{Register-Markierung}\label{sycl:erweiterungen:intel:register}

Um dem Programmierer mehr Kontrolle über die Ressource des generierten
Bitstreams zu geben und um den Compiler bei der Synthese eines effizienten
Bitstreams zu unterstützen, können Variablen durch die Erweiterung
\texttt{fpga\_reg} direkt in einem Register platziert werden (siehe
Quelltext~\ref{sycl:erweiterungen:intel:register:src}). Wie das Beispiel zeigt,
lassen sich auf diese Art auch ganze Felder in einzelne Register zerlegen.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto c = cl::sycl::intel::fpga_reg(a[k]) + b[k];
    \end{minted}
    \caption{Zuordnung einer Variable zu einem FPGA-Register}
    \label{sycl:erweiterungen:intel:register:src}
\end{code}

\subsection{Xilinx-FPGAs}\label{sycl:erweiterungen:xilinx}

Der im Rahmen des triSYCL-Projekts entwickelte Compiler basiert auf der
Intel-Implementierung und wird maßgeblich von Xilinx entwickelt. Aus diesem
Grund finden sich in dieser Implementierung einige Erweiterungen, die auf den
Einsatz von Xilinx-\gls{fpga}s zugeschnitten sind. Diese sind in der
Header-Datei \texttt{CL/sycl/xilinx/fpga.hpp} definiert und werden in den
folgenden Abschnitten vorgestellt.

\subsubsection{Datenflussorientierte Ausführung}
\label{sycl:erweiterungen:xilinx:dataflow}

Aus Xilinx' OpenCL-Implementierung übernimmt der triSYCL-Compiler eine
datenflussbasierte Erweiterung. Diese Erweiterung ermöglicht die task-parallele
Ausführung aufeinanderfolgender Funktionen und Schleifen. Mit ihr wird der
Compiler angewiesen, die Abhängigkeiten zwischen den einzelnen Schritten zu
analysieren und für diese Schritte das
\textit{Producer}/\textit{Consumer}-Prinzip durch eine Zwischenschaltung von
Puffern durchzusetzen. \cite[siehe][70\psqq]{sdaccelopt2019}

In OpenCL ist diese Erweiterung als \texttt{xcl\_dataflow} verfügbar und wird
im OpenCL"=C"=Dialekt einem Kernel, einer Funktion oder einer Schleife als
Attribut zugewiesen (siehe
Quelltext~\ref{sycl:erweiterungen:xilinx:dataflow:opencl}). Der
SYCL-Implementierung steht diese Erweiterung unter dem Namen \texttt{dataflow}
zur Verfügung. Mit ihr werden Funktionen markiert, auf deren innere Funktionen
und Schleifen die entsprechenden Bitstream-Optimierungen angewandt werden (siehe
Quelltext~\ref{sycl:erweiterungen:xilinx:dataflow:sycl}).

\begin{code}
    \begin{minted}[fontsize=\small,escapeinside=||]{c}
|\textbf{\textcolor{keyword-green}{\_\_kernel}}| __attribute__((xcl_dataflow))
void kernel(/* ... */)
{
    /* Funktionskörper */
}
    \end{minted}
    \caption{Datenfluss-Erweiterung in OpenCL C}
    \label{sycl:erweiterungen:xilinx:dataflow:opencl}
\end{code}

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto body(/* ... */)
{
    /* Funktionskörper */
}

struct kernel
{
    auto operator()()
    {
        cl::sycl::xilinx::dataflow(body(/* ... */));
    }
};
    \end{minted}
    \caption{Datenfluss-Erweiterung in SYCL}
    \label{sycl:erweiterungen:xilinx:dataflow:sycl}
\end{code}

\subsubsection{Pipeline-basierte Ausführung}
\label{sycl:erweiterungen:xilinx:pipeline}

Die triSYCL-Implementierung übernimmt aus Xilinx' OpenCL-Umgebung eine
pipeline-basierte Erweiterung. Mit dieser kann der Compiler angewiesen werden,
die Iterationen einer Schleife zu überlappen. Dadurch können die Iterationen
bestimmte Ressourcen zeitgleich nutzen, wodurch sich der Ressourcenverbrauch
insgesamt sowie die Latenz verringern können.
\cite[siehe][67\psqq]{sdaccelopt2019}

In der von Xilinx ausgelieferte OpenCL-Implementierung handelt es sich bei
dieser Erweiterung um das Attribut \texttt{xcl\_pipeline\_loop}, mit dem
Schleifen markiert werden (siehe
Quelltext~\ref{sycl:erweiterungen:xilinx:pipeline:opencl}). In SYCL ist sie
unter dem Namen \texttt{pipeline} verfügbar und wird auf Funktionen angewendet,
deren innere Schleifen dann dieser Optimierung unterzogen werden (siehe
Quelltext~\ref{sycl:erweiterungen:xilinx:pipeline:sycl}).

\begin{code}
    \begin{minted}[fontsize=\small,escapeinside=||]{c}
|\textbf{\textcolor{keyword-green}{\_\_kernel}}| void kernel(/* ... */)
{
    __attribute__((xcl_pipeline_loop))
    for(int i = 0; i < 32; ++i)
    {
        /* Schleifenkörper */
    }
}
    \end{minted}
    \caption{Pipeline-Erweiterung in OpenCL C}
    \label{sycl:erweiterungen:xilinx:pipeline:opencl}
\end{code}

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto body(/* ... */)
{
    for(int i = 0; i < 32; ++i)
    {
        /* Schleifenkörper */
    }
}

struct kernel
{
    auto operator()()
    {
        cl::sycl::xilinx::pipeline(body(/* ... */));
    }
};
    \end{minted}
    \caption{Pipeline-Erweiterung in SYCL}
    \label{sycl:erweiterungen:xilinx:pipeline:sycl}
\end{code}

\subsubsection{Feldpartitionierung}
\label{sycl:erweiterungen:xilinx:partitioning}

Durch die Verteilung eines Datenfeldes auf mehrere physische Speichersegmente
lässt sich für manche Anwendungen eine höhere Speicherbandbreite erzielen.
Mit Xilinx' High-Level-Synthese lässt sich ein logisches Datenfeld auf drei
verschiedene Weisen zerlegen: \textit{cyclic}, \textit{block} und
\textit{complete}. \cite[vgl.][16]{sdxpragma2019}

Der Typ \textit{cyclic} führt eine zyklische Zerlegung des Feldes durch. Geht
man von einem acht-elementigen Feld aus und hat vier physische Speicher zur
Verfügung, so werden die Elemente einzeln in aufsteigender Reihenfolge auf die
Speicher aufgeteilt: Element 0 wird dem Speicher 0 zugeordnet, Element 1 dem
Speicher 1, und so weiter. Ist Speicher 3 erreicht, beginnt die Zuteilung wieder
von vorne, Element 4 wird dem Speicher 0 zugeordnet, Element dem Speicher 1,
und so weiter. \cite[vgl.][17]{sdxpragma2019}

Der Typ \textit{block} zerlegt das Feld blockweise. Das heißt, dass zuerst der
Speicher 0 mit den ersten Elementen des Feldes befüllt wird, dann der Speicher
1, und so weiter. \cite[vgl.][17]{sdxpragma2019}

Beim Typ \textit{complete} wird das Feld in einzelne Elemente zerlegt. Dies
entspricht einer Verteilung des Feldes auf einzelne Register.
\cite[vgl.][17]{sdxpragma2019}

Das Attribut \texttt{xcl\_array\_partition(<Typ>, <Faktor>, <Dimension>)} steht
als Erweiterung in Xilinx' OpenCL-Implementierung zur Verfügung, um die
Partitionierung durchzuführen. Dabei bezeichnet \texttt{<Typ>} einen der drei
oben genannten Typen. \cite[vgl.][17]{sdxpragma2019}

\texttt{<Faktor>} gibt für \textit{cyclic} die Anzahl der Speicher an, auf die
das Feld verteilt werden soll, und für \textit{block} die Anzahl der Elemente
pro Speicher. Für den Typ \textit{complete} ist dieser Parameter nicht
definiert. \cite[vgl.][17]{sdxpragma2019}

\texttt{<Dimension>} gibt an, welche Dimension des Feldes auf die beschriebene
Weise partitioniert werden soll. \cite[vgl.][17]{sdxpragma2019}

Der Quelltext~\ref{sycl:erweiterungen:xilinx:partitioning:opencl} zeigt den
Gebrauch dieser Erweiterung in einem OpenCL-Kernel.

In SYCL steht diese Erweiterung unter dem Namen \texttt{partition\_array} zur
Verfügung, wobei die Zuweisung der oben aufgeführten Parameter hier über
Templates erfolgt. Der
Quelltext~\ref{sycl:erweiterungen:xilinx:partitioning:sycl} zeigt die Anwendung
dieser Erweiterung.

\begin{code}
    \begin{minted}[fontsize=\small,escapeinside=||]{c}
|\textbf{\textcolor{keyword-green}{\_\_kernel}}| void kernel(/* ... */)
{
    // zyklische Verteilung von a auf 4 physische Speicher
    int a[16] __attribute__((xcl_array_partition(cyclic, 4, 1)));

    // blockweise Verteilung von b mit 4 Elementen pro physischem Speicher
    int b[16] __attribute__((xcl_array_partition(block, 4, 1)));

    // Zerlegung von c in 16 Register
    int c[16] __attribute__((xcl_array_partition(complete, 1)));
}
    \end{minted}
    \caption{Feldpartitionierung in OpenCL C}
    \label{sycl:erweiterungen:xilinx:partitioning:opencl}
\end{code}

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
struct kernel
{
    auto operator()()
    {
        // zyklische Verteilung von a auf 4 physische Speicher
        auto a = cl::sycl::xilinx::partition_array<int, 16,
                    cl::sycl::xilinx::partition::cyclic<4, 1>>{};

        // blockweise Verteilung von b mit 4 Elementen pro physischem Speicher
        auto b = cl::sycl::xilinx::partition_array<int, 16,
                    cl::sycl::xilinx::partition::block<4, 1>>{};

        // Zerlegung von c in 16 Register
        auto c = cl::sycl::xilinx::partition_array<int, 16,
                    cl::sycl::xilinx::partition::complete<1>>{};
    }
};
    \end{minted}
    \caption{Feldpartitionierung in SYCL}
    \label{sycl:erweiterungen:xilinx:partitioning:sycl}
\end{code}
