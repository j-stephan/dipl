\chapter{Der SYCL-Standard}\label{sycl}

Die vor einigen Jahren veröffentlichte SYCL"=Spezifikation bietet eine neue
Möglichkeit, um ein Problem auf algorithmischer Ebene zu formulieren und dann
über die HLS in eine \gls{fpga}"=Schaltung zu synthetisieren. Eine einfache
SYCL"=Einführung sowie die für \gls{fpga}s wichtigen Besonderheiten sind daher
das Thema dieses Kapitels.

\section{Überblick}\label{sycl:ueberblick}

Mit dem SYCL"=Standard\footnote{Entgegen des optischen Anscheins ist
\glqq SYCL\grqq\ kein Akronym, sondern ein Eigenname.}\cite[vgl.][]{sycl2019}
verfolgt die herausgebende Khronos"=Gruppe das Ziel eines abstrakten
C++"=Programmiermodells für \gls{opencl}, das die Flexibilität und
Einfachheit moderner C++"=Standards bieten soll, während gleichzeitig
Konzeption und Portabilität des \gls{opencl}"=1.2"=Standards
\cite[vgl.][]{opencl2012} beibehalten werden.

Von \gls{opencl} erbt SYCL damit den Anspruch, ein einheitliche
Programmierschnittstelle für verschiedene Beschleunigertypen unterschiedlicher
Hersteller zu bieten. Das heißt, dass ein einmal geschriebener Quelltext, der
auf einem Beschleuniger ausgeführt werden soll, möglichst ohne große Änderungen
sowohl auf einer \gls{cpu}, einer \gls{gpu}, einem \gls{dsp} oder einem
\gls{fpga} ausführbar sein soll.

SYCL unterscheidet sich von \gls{opencl} im Hinblick auf die Struktur des
Quelltextes: bei \gls{opencl} sind die Quelltexte für das steuernde Programm
(\textit{Host}) und den Programmteil, der vom Beschleuniger (\textit{Device})
ausgeführt wird, voneinander getrennt. Diese Design"=Entscheidung des
\gls{opencl}"=Standards ist durch das Ziel der Plattformunabhängigkeit
begründet: ein Entwickler kennt während der Kompilierung des Hauptprogramms
nicht notwendigerweise die vorhandenen Beschleuniger der Zielplattform. Dadurch
wird der \textit{Device}"=spezifische Quelltext häufig erst zur Laufzeit des
Programms kompiliert, da in diesem Moment der konkrete Beschleuniger bekannt
ist. Dieser Ansatz hat jedoch den Nachteil, dass der Compiler des
\textit{Device}"=Quelltexts (im Folgenden als \textit{Kernel} bezeichnet) keine
Annahmen mehr über das \textit{Host}"=Programm bzw. den den \textit{Kernel}
umgebenden Quelltext mehr treffen kann, was zu einem geringeren
Optimierungspotential führt. \gls{opencl}"=Kernel lassen sich zwar auch vor
der Laufzeit des Programms für eine konkrete Zielplattform kompilieren (dies
geschieht aufgrund der langen Kompilierungszeiten bei \gls{fpga}s), büßen
dadurch aber ihre Plattformunabhängigkeit ein.

Ein SYCL-Quelltext kennt dagegen keine strikte Trennung zwischen \textit{Host}-
und \textit{Device}"=Anweisungen. Neben der besseren Analyse des den
\textit{Kernel} umgebenden Kontexts hat dies den weiteren Vorteil, dass
\textit{Host} und \textit{Device} Quelltext teilen können, wie etwa den
beidseitig verwendeter Hilfsfunktionen. Der \textit{Kernel} wird dabei vom
\textit{Device}"=Compiler extrahiert und in eine Form umgewandelt, die von der
Ziel"=Hardware zur Laufzeit kompiliert oder ausgeführt werden kann.
\cite[vgl][35]{sycl2019}

Ein weiterer wichtiger Unterschied zu \gls{opencl} besteht darin, dass
jedes SYCL"=Programm mit einem Standard"=C++"=Compiler übersetzt werden kann,
sofern keine direkten Interaktionen mit \gls{opencl} selbst erfolgen. Damit
lässt sich ein SYCL"=Programm auf jeder \gls{cpu} ausführen, für die ein
(moderner) C++"=Compiler existiert, wenngleich dies Einschränkungen bei der
erreichbaren Leistung bedeuten kann. So schreibt die SYCL"=Spezifikation für
diesen Fall nur die Ausführbarkeit selbst vor, aber nicht die Nutzung aller
\gls{cpu}"=Kerne oder SIMD"=Register. \cite[vgl.][15]{sycl2019}

Seit der ersten Veröffentlichung im März 2014 \cite[vgl.][]{khronos2014} mit der
Versionsnummer 1.2 wurde die SYCL"=Spezifikation stetig weiterentwickelt; die
zur Zeit aktuelle Spezifikation vom April 2019 trägt die Revisionsnummer 1.2.1
Revision 5. \cite[vgl.][1]{sycl2019}

Teil der Khronos"=Gruppe sind (unter anderen) die \gls{fpga}"=Hersteller Xilinx
und Intel. Xilinx unterstützt den SYCL"=Standard in Form einer Erweiterung der
bestehenden HLS"=Werkzeuge bereits, während Intel dies für die eigenen FPGAs
mittelfristig plant; für Intel"=\gls{cpu}s und "=\gls{gpu}s ist bereits eine
SYCL"=Implementierung verfügbar (der Abschnitt~\ref{sycl:implementierungen}
befasst sich mit allen verfügbaren Implementierungen).

\subsection{AXPY und SYCL}\label{sycl:ueberblick:saxpy}

Ein im Bereich der Programmierung häufig verwendetes einführendes Beispiel
ist der sogenannte AXPY"=Algorithmus, der ursprünglich aus der Bibliothek
\gls{blas} stammt \cite[vgl.][]{lawson1979}. Dieser führt die Berechnung
\[\vec{y} = a \cdot \vec{x} + \vec{y}\]
aus und ist aufgrund seiner Einfachheit und hohen erreichbaren Parallelität
(sofern $\vec{x}$ und $\vec{y}$ viele Elemente enthalten) sehr beliebt.

AXPY lässt sich auch für eine Einführung in SYCL gut verwenden und wird daher in
den folgenden Abschnitten als illustrierendes Beispiel genutzt.

Ein SYCL"=Programm lässt sich in mehrere aufeinander aufbauende Stufen
unterteilen, wie in Quelltext~\ref{sycl:ueberblick:saxpy:struktur} zu sehen ist.
Die einzelnen Platzhalter im Quelltext werden in den nächsten Abschnitten mit
Inhalt gefüllt.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
#include <cstdlib>

#include <CL/sycl.hpp>

auto main() -> int
{
    // Beschleunigerwahl und Befehlswarteschlange

    // Speicherreservierung und -initialisierung

    // Kerneldefinition und -ausführung

    // Synchronisierung

    return EXIT_SUCCESS;
}
    \end{minted}
    \caption{Struktur eines SYCL-Programms}
    \label{sycl:ueberblick:saxpy:struktur}
\end{code}

\subsubsection{Beschleunigerwahl und Befehlswarteschlange}
\label{sycl:ueberblick:saxpy:queue}

Von \gls{opencl} erbt SYCL die Plattformunabhängigkeit. Es wird das
Vorhandensein mindestens einer \gls{opencl}"=Plattform auf dem System
angenommen\footnote{Aber nicht vorausgesetzt! Jede SYCL"=Implementierung muss
auch ohne eine OpenCL"=Plattform auf dem Host lauffähig sein.}, was im
Umkehrschluss bedeutet, dass unter Umständen zwischen mehreren, verschiedenen
Plattformen konkurrierender Hersteller gewählt werden muss.
% Bitte vollständigen Satz in Fußnote

Die SYCL"=Spezifikation bietet dem Programmierer mehrere Möglichkeiten, die
gewünschte Plattform für sein Programm auszuwählen. Der einfachste Ansatz
besteht darin, eine Befehlswarteschlange (die \texttt{queue} genannt wird) für
einen Beschleuniger zu konstruieren. Über die Befehlswarteschlange erfolgt die
Kommunikation zwischen dem \textit{Host} und einem \textit{Device}, also
Kopieroperationen, das Starten eines \textit{Kernels} sowie die
Synchronisierung. Letztere ist notwendig, da es sich bei dem \textit{Device}
um eine vom \textit{Host} weitestgehend unabhängige Hardware handelt, die
Operationen also (aus Sicht des \textit{Hosts}) asynchron ablaufen.

Jedes genutzte \textit{Device} erhält in SYCL mindestens eine eigene
\texttt{queue}, so dass auch die Nutzung mehrerer Beschleuniger möglich ist.

Eine \texttt{queue} kann durch das Übergeben eines Auswahlkriteriums für das
gewünschte \textit{Device} konstruiert werden. Die Auswahlkriterien werden in
der SYCL"=Spezifikation \texttt{device\_selector} genannt. Neben den in der
Spezifikation vorhandenen Kriterien (beispielsweise \texttt{cpu\_selector},
\texttt{gpu\_selector} oder \texttt{host\_selector}) ist es Herstellern oder dem
Programmierer selbst möglich, durch das Erben von der Elternklasse
\texttt{device\_selector} eigene Kriterien zu definieren. Beispielsweise findet
sich in den Testfällen der von Xilinx entwickelten SYCL"=Implementierung ein
\texttt{device\_selector} für die eigenen Geräte, der die \gls{fpga}s über den
Firmennamen findet. Mit dessen Hilfe lässt sich die Befehlswarteschlange für
einen Xilinx"=FPGA wie in Quelltext~\ref{sycl:ueberblick:saxpy:queue:src}
dargestellt erzeugen.
%
\begin{code}
    \begin{minted}[fontsize=\small]{c++}
class XOCLDeviceSelector : public cl::sycl::device_selector {
    public:
        int operator()(const cl::sycl::device &Device) const override {
            const std::string DeviceVendor =
                            Device.get_info<cl::sycl::info::device::vendor>();
            return (DeviceVendor.find("Xilinx") != std::string::npos) ? 1 : -1;
        }
};

/* ... */

auto queue = cl::sycl::queue{XOCLDeviceSelector{}};
    \end{minted}
    \caption{Auswahl eines Xilinx"=FPGAs und Erzeugung einer zugehörigen
             Befehlswarteschlange}
    \label{sycl:ueberblick:saxpy:queue:src}
\end{code}
%
\noindent
Programmierern, die mehr Kontrolle über die Initialisierung des Beschleunigers
oder der gesamten SYCL"=Laufzeitumgebung wünschen, stellt die
SYCL"=Spezifikation das aus \gls{opencl} bekannte Schema zur Verfügung. Der
Programmierer kann zunächst eine Liste aller zur Verfügung stehenden
\gls{opencl}"=Plattformen anfordern, aus denen er frei wählen kann. Auf dem
Fundament der gewählten Plattform erzeugt der Programmierer im nächsten Schritt
einen SYCL"=Kontext (der einen \gls{opencl}"=Kontext kapselt). Der Kontext
stellt wiederum eine Liste aller \textit{Devices} der Plattform bereit, aus der
ein oder mehrere Beschleuniger ausgesucht werden können. Die Auswahl dient dann
als Parameter für die Erzeugung einer SYCL"=Befehlswarteschlange. In jedem
der genannten Schritte stehen dem Programmierer zahlreiche Informationen über
die jeweilige Klasse zur Verfügung (Hersteller der Plattform oder des
Beschleunigers, Hardware"=Eigenschaften, verfügbare Erweiterungen, usw.), die
eine Verfeinerung der Auswahl erlauben.

Der Quelltext~\ref{sycl:ueberblick:saxpy:queue:ausfuehrlich} zeigt das
ausführliche Schema, in den folgenden Abschnitten wird jedoch die oben gezeigte,
einfachere und kürzere Variante verwendet.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto platforms = cl::sycl::platform::get_platforms();
auto my_platform = /* ... */;

auto context = cl::sycl::context{my_platform};

auto devices = context.get_devices();
auto my_device = /* ... */;

auto queue = cl::sycl::queue{my_device};
    \end{minted}
    \caption{Ausführliche Beschleunigerwahl und Befehlswarteschlangen"=Konstruktion}
    \label{sycl:ueberblick:saxpy:queue:ausfuehrlich}
\end{code}

\subsubsection{Speicherreservierung und -initialisierung}
\label{sycl:ueberblick:saxpy:buffer}

Für die Vektoren $\vec{x}$ und $\vec{y}$ ist eine Speicherreservierung auf dem
\textit{Device} sowie die Initialisierung des reservierten Speichers notwendig
(die Konstante $a$ kann als einfacher Parameter übergeben werden). SYCL stellt
dafür zwei Klassen bereit:
%
\begin{itemize}
    \item Ein \texttt{buffer} kapselt die auf dem \textit{Device} reservierten
          Speicherbereiche. Dabei ist zu beachten, dass ein \texttt{buffer}
          keinem \textit{Device} direkt zugeordnet ist, sondern dem gesamten
          Kontext zur Verfügung steht. Ein \texttt{buffer} kann so auch auf
          mehreren \textit{Devices} verwendet werden, die notwendige
          Synchronisierung wird von der SYCL"=Laufzeitumgebung vorgenommen.
    \item Ein \texttt{accessor} sorgt für den Zugriff auf den von einem
          \texttt{buffer} verwalteten Speicher. Es existieren verschiedene
          \texttt{accessor}"=Typen, darunter auch einer für den Speicherzugriff
          auf der \textit{Host}"=Seite. Mit diesem lässt sich ein
          \texttt{buffer} direkt initialisieren, ohne eine explizite Kopie
          anstoßen zu müssen. Aus Sicht des Programmierers lässt sich ein
          \texttt{accessor} wie ein Zeiger oder Feld verwenden, d.h. über den
          \texttt{[]}"=Operator.
\end{itemize}
%
\noindent
Ein \texttt{buffer} besteht aus einer endlichen Anzahl von Elementen desselben
Typs und kann ein-, zwei- oder dreidimensional sein. Der Elemente-Typ sowie die
Dimension des Puffers sind als Template"=Parameter zur Compile"=Zeit anzugeben,
während die Anzahl als Laufzeit"=Parameter übergeben wird. Ein \texttt{accessor}
lässt sich über die Methode \texttt{get\_access} der \texttt{buffer}"=Klasse
erzeugen. Dabei wird als Template"=Parameter der gewünschte Zugriffstyp
angegeben. Diese Information wird von der SYCL"=Laufzeitumgebung zur Sortierung
der Abhängigkeiten zwischen Operationen auf dem \textit{Device} genutzt (siehe
auch Abschnitt~\ref{sycl:konzepte:abhaengigkeiten}).

SYCL unterscheidet sechs verschiedene Zugriffstypen:
\begin{itemize}
    \item \texttt{read} gestattet ausschließlich lesenden Zugriff auf den
          Puffer.
    \item \texttt{write} ermöglicht ausschließlich schreibenden Zugriff.
    \item Durch \texttt{read\_write} kann sowohl lesend als auch schreibend
          auf den \texttt{buffer} zugegriffen werden.
    \item \texttt{discard\_write} ermöglicht ausschließlich schreibenden Zugriff
          und verwirft alle vorher im Puffer enthaltenen Elemente (also auch bei
          partiellem Zugriff).
    \item \texttt{discard\_read\_write} ist die Kombination aus
          \texttt{read\_write} und \texttt{discard\_write}.
    \item \texttt{atomic} ermöglicht atomaren Zugriff bei paralleler Nutzung des
          Puffers.
\end{itemize}

Für das AXPY"=Beispiel lassen sich die benötigten Felder wie in
Quelltext~\ref{sycl:ueberblick:saxpy:buffer:src} dargestellt anlegen und
initialisieren.
%
\begin{code}
    \begin{minted}[fontsize=\small]{c++}
// Puffer enthalten 1024 Elemente
const auto buf_range = cl::sycl::range<1>{1024};

// erzeuge eindimensionale Puffer für int-Elemente
auto buf_x = cl::sycl::buffer<int, 1>{buf_range};
auto buf_y = cl::sycl::buffer<int, 1>{buf_range};

// greife auf x und y zu, verwirf vorherige Elemente
auto h_acc_x = buf_x.get_access<cl::sycl::access::mode::discard_write>();
auto h_acc_y = buf_x.get_access<cl::sycl::access::mode::discard_write>();

// initialisiere x und y
for(auto i = 0; i < 1024; ++i)
{
    h_acc_x[i] = /* ... */;
    h_acc_y[i] = /* ... */;
}
    \end{minted}
    \caption{Speicherreservierung und -initialisierung in SYCL}
    \label{sycl:ueberblick:saxpy:buffer:src}
\end{code}

\subsubsection{Kerneldefinition und -ausführung}
\label{sycl:ueberblick:saxpy:kernel}

Im nächsten Schritt wird der eigentliche Kernel definiert und ausgeführt. Ein
SYCL"=Kernel besteht aus zwei Teilen: der eigentlichen Kernel"=Funktion, also
der Abbildung des Algorithmus auf SYCL"=C++"=Quelltext, sowie den Abhängigkeiten
(in Form von \texttt{accessor}"=Variablen). Kernel"=Funktion und Abhängigkeiten
bilden gemeinsam eine \textit{command group} und werden in dieser Form an die
\texttt{queue} zur Ausführung übergeben. Dabei kann jede \textit{command group}
nur genau eine Kernel"=Funktion (oder explizite Kopieroperation) enthalten. Es
bildet sich damit für das AXPY"=Beispiel das in
Quelltext~\ref{sycl:ueberblick:saxpy:kernel:cg} gezeigte Grundgerüst einer
\textit{command group}, welche in diesem Fall als C++"=Lambdafunktion notiert
wird.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
[&](cl::sycl::handler& cgh)
{
    auto d_acc_x = buf_x.get_access<cl::sycl::access::mode::read>(cgh);
    auto d_acc_y = buf_y.get_access<cl::sycl::access::mode::read_write>(cgh);

    // Kernel-Funktionsaufruf
}
    \end{minted}
    \caption{Struktur einer \textit{command group}}
    \label{sycl:ueberblick:saxpy:kernel:cg}
\end{code}

SYCL bietet für verschiedene Anwendungsfälle unterschiedliche Methoden für den
Aufruf der Kernel"=Funktion. Für datenparallele Algorithmen bietet sich vor
allem der Aufruf mittels der Methode \texttt{parallel\_for} an. Diese
entspricht dem aus \gls{opencl} bekannten \textit{NDRange}"=Kernel und nutzt die
SIMD"=Eigenschaften der zur Verfügung stehenden Beschleuniger. Auf CPUs können
so durch einen Aufruf mehrere Kerne und deren SIMD"=Register genutzt werden oder
auf einer GPU die Multiprozessoren und SIMD"=Einheiten. Auf einem FPGA kann
durch \texttt{parallel\_for} ebenfalls eine SIMD"=Schaltung synthetisiert
werden. 

Für aufgabenparallele Algorithmen steht in SYCL der Aufruf \texttt{single\_task}
zur Verfügung, was einem \textit{Task}"=Kernel in \gls{opencl} entspricht.
Dieser wird z.B. auf einer CPU nur auf einem einzelnen Kern ausgeführt. Mehrere
Kernel dieses Typs lassen sich dann parallel auf den vorhandenen Kernen
ausführen.

Für das AXPY"=Beispiel bietet sich der datenparallele Fall an, weshalb die
Kernel"=Funktion aufgerufen wird (siehe Quelltext~\ref{sycl:ueberblick:saxpy:kernel:call}).
Die \num{1024} Elemente der Vektoren werden dabei als
Arbeitsgröße mit übergeben. Die SYCL"=Laufzeitumgebung generiert daraus einen
Ausführungsraum mit \num{1024} \textit{work-items}, einer Abstraktion der
zugrundeliegenden Hardware"=Features (SIMD"=Register, Threads, usw.). Der Index
des jeweiligen \textit{work-items} wird als Parameter an die Kernel"=Funktion
übergeben und kapselt einen Index, der für den Zugriff auf ein Element im
Speicher verwendet werden kann.
% Verweis auf Abschnitt zur Erklärung work-items, blöcke, threads, ...? Transparent Scalability?

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
[&](cl::sycl::handler& cgh)
{
    auto d_acc_x = buf_x.get_access<cl::sycl::access::mode::read>(cgh);
    auto d_acc_y = buf_y.get_access<cl::sycl::access::mode::read_write>(cgh);

    cgh.parallel_for<class axpy>(cl::sycl::range<1>{1024},
    [=](cl::sycl::item<1> work_item)
    {
        auto idx = work_item.get_id();
        d_acc_y[idx] = a * d_acc_x[idx] + d_acc_y[idx];
    });
}
    \end{minted}
    \caption{Struktur einer \textit{command group} mit Kernel"=Aufruf}
    \label{sycl:ueberblick:saxpy:kernel:call}
\end{code}

\subsubsection{Synchronisierung}
\label{sycl:ueberblick:saxpy:sync}

Nachdem der Kernel an die Befehlswarteschlange übergeben wurde, muss das
Ergebnis überprüft werden. Um darauf zugreifen zu können, ist zunächst die
Synchronisierung von \textit{Host} und \textit{Device} erforderlich, da beide
asynchron zueinander arbeiten. Die \texttt{queue} verfügt jedoch über die
Methode \texttt{wait}, die den \textit{Host} so lange warten lässt, bis alle bis
zu diesem Zeitpunkt eingereihten Befehle abgearbeitet wurden. Dies ist in
Quelltext~\ref{sycl:ueberblick:saxpy:sync:wait} dargestellt. Anschließend
lassen sich die Elemente des Vektors $\vec{y}$ auf der \textit{Host}"=Seite
über den während der Initialisierung der Puffer angelegten \texttt{accessor}
überprüfen.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
queue.wait();
    \end{minted}
    \caption{Struktur einer \textit{command group} mit Kernel"=Aufruf}
    \label{sycl:ueberblick:saxpy:sync:wait}
\end{code}

\subsubsection{Zusammenfassung}
\label{sycl:ueberblick:saxpy:zusammenfassung}

Das gesamte SYCL"=AXPY"=Beispiel findet sich in
Quelltext~\ref{sycl:ueberblick:saxpy:zusammenfassung:code}, einschließlich
einiger kleinerer, in den vorigen Abschnitten ausgelassener, Details.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
#include <cstdlib>
#include <CL/sycl.hpp>

class XOCLDeviceSelector : public cl::sycl::device_selector {
    public:
        int operator()(const cl::sycl::device &Device) const override {
            const std::string DeviceVendor =
                            Device.get_info<cl::sycl::info::device::vendor>();
            return (DeviceVendor.find("Xilinx") != std::string::npos) ? 1 : -1;
        }
};

auto main() -> int {
    constexpr auto a = 42;

    // Beschleunigerwahl und Befehlswarteschlange
    auto queue = cl::sycl::queue{XOCLDeviceSelector{}};

    // Speicherreservierung und -initialisierung
    const auto buf_range = cl::sycl::range<1>{1024};

    auto buf_x = cl::sycl::buffer<int, 1>{buf_range};
    auto buf_y = cl::sycl::buffer<int, 1>{buf_range};

    auto h_acc_x = buf_x.get_access<cl::sycl::access::mode::discard_write>();
    auto h_acc_y = buf_x.get_access<cl::sycl::access::mode::discard_write>();

    for(auto i = 0; i < 1024; ++i)
    {
        h_acc_x[i] = /* ... */;
        h_acc_y[i] = /* ... */;
    }

    // Kerneldefinition und -ausführung
    queue.submit([&](cl::sycl::handler& cgh)
    {
        auto d_acc_x = buf_x.get_access<cl::sycl::access::mode::read>(cgh);
        auto d_acc_y = buf_y.get_access<cl::sycl::access::mode::read_write>(cgh);

        cgh.parallel_for<class axpy>(cl::sycl::range<1>{1024},
        [=](cl::sycl::item<1> work_item)
        {
            auto idx = work_item.get_id();
            d_acc_y[idx] = a * d_acc_x[idx] + d_acc_y[idx];
        });
    });

    // Synchronisierung
    queue.wait();

    return EXIT_SUCCESS;
}
    \end{minted}
    \caption{AXPY -- vollständiges SYCL"=Beispiel}
    \label{sycl:ueberblick:saxpy:zusammenfassung:code}
\end{code}

\section{Weiterführende Konzepte}\label{sycl:konzepte}

Die Entwicklung komplexerer Programme mit SYCL erfordert die Kenntnis einiger
weiterer Konzepte, die in der obigen Einführung nicht berücksichtigt wurden.
Dazu zählen die in SYCL vorhandene Hardware"=Abstraktion sowie die
Abhängigkeiten zwischen Kerneln. Für die Analyse des entwickelten Programms
sind außerdem SYCLs Fähigkeiten zur Fehlerbehandlung und zum Profiling relevant.

\subsection{Hardware"=Abstraktion}

Um eine bessere Anpassung des Programms auf die genutzte Hardware zu
ermöglichen, ohne die Plattformunabhängigkeit aufzugeben, führte die
\gls{opencl}"=Spezifikation eine Reihe von Abstraktionen ein. Diese entsprechen
konzeptionell den in der Hardware vorhandenen Fähigkeiten und wurden ebenfalls
von SYCL übernommen.

Eine \textit{Plattform} ist in OpenCL und SYCL aus dem \textit{Host} und
mindestens einem \textit{Device} zusammengesetzt. Jedes \textit{Device} besteht
wiederum aus mindestens einer \textit{compute unit} (CU). Eine CU lässt sich auf
einen oder mehrere Teile des Beschleunigers abbilden und ist in der Lage, einen
Kernel auszuführen. Bei einer CPU lässt sich eine CU also auf einen
Kern abbilden oder bei einer GPU auf einen Multiprozessor. Bei FPGAs ist die
Abbildung dynamischer: hier hängt die Zahl der verfügbaren CUs davon ab, wie
viele Ressourcen der Kernel verbraucht. Die Zahl der gleichzeitig platzierbaren
Kernel entspricht damit der Zahl der möglichen CUs, sofern die Implementierung
keine Obergrenze für die CU"=Anzahl vorgibt. Eine CU besteht aus mindestens
einem \textit{processing element} (PE). Ein PE lässt sich dabei als Abstraktion
der SIMD"=Fähigkeiten einer CU verstehen, also z.B. als ein Element innerhalb
eines SIMD"=Vektorregisters.
Die Abbildung~\ref{sycl:konzepte:abstraktion:plattform} veranschaulicht dieses
Modell.

\begin{figure}
    \centering
    \begin{tikzpicture}
        % hinterstes Device
        \draw [fill = white] (2.499, 2.499) rectangle ++(5, 2.5);
        \draw [fill = white] (4.249, 3.416) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (4.349, 3.516) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (4.749, 3.516) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (5.149, 3.516) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (6.949, 3.516) rectangle ++(0.2, 1.133);
        \draw [fill = white] (3.499, 3.0825) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (3.599, 3.1825) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.999, 3.1825) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (4.399, 3.1825) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (6.199, 3.1825) rectangle ++(0.2, 1.133);
        \draw [fill = white] (2.749, 2.749) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (2.849, 2.849) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.249, 2.849) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.649, 2.849) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (5.449, 2.849) rectangle ++(0.2, 1.133);

        % erstes von hinten
        \draw [fill = white] (1.666, 1.666) rectangle ++(5, 2.5);
        \draw [fill = white] (3.416, 2.583) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (3.516, 2.683) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.916, 2.683) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (4.316, 2.683) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (6.116, 2.683) rectangle ++(0.2, 1.133);
        \draw [fill = white] (2.666, 2.2495) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (2.766, 2.3495) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.166, 2.3495) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.566, 2.3495) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (5.366, 2.3495) rectangle ++(0.2, 1.133);
        \draw [fill = white] (1.916, 1.916) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (2.016, 2.016) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.416, 2.016) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.816, 2.016) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (4.616, 2.016) rectangle ++(0.2, 1.133);

        % zweites von hinten
        \draw [fill = white] (0.833, 0.833) rectangle ++(5, 2.5);
        \draw [fill = white] (2.583, 1.75) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (2.683, 1.85) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.083, 1.85) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.483, 1.85) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (5.283, 1.85) rectangle ++(0.2, 1.133);
        \draw [fill = white] (1.833, 1.4165) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (1.933, 1.5165) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.333, 1.5165) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.733, 1.5165) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (4.533, 1.5165) rectangle ++(0.2, 1.133);
        \draw [fill = white] (1.083, 1.083) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (1.183, 1.183) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (1.583, 1.183) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (1.983, 1.183) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.783, 1.183) rectangle ++(0.2, 1.133);

        % vorderstes Device
        \draw [fill = white] (0.0, 0.0) rectangle ++(5, 2.5);
        \draw [fill = white] (1.75, 0.917) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (1.85, 1.017) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.25, 1.017) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.65, 1.017) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (4.45, 1.017) rectangle ++(0.2, 1.133);
        \draw [fill = white] (1.0, 0.5835) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (1.1, 0.6835) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (1.5, 0.6835) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (1.9, 0.6835) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (3.7, 0.6835) rectangle ++(0.2, 1.133);
        \draw [fill = white] (0.25, 0.25) rectangle ++(3, 1.333);
        \draw [fill = HKS41!20] (0.35, 0.35) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (0.75, 0.35) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (1.15, 0.35) rectangle ++(0.2, 1.133);
        \draw [fill = HKS41!20] (2.95, 0.35) rectangle ++(0.2, 1.133);
        % Punkte sind nur hier notwendig, Rest wird überdeckt
        \draw [fill = black] (1.825, 0.9165) circle [radius = 0.5mm];
        \draw [fill = black] (2.125, 0.9165) circle [radius = 0.5mm];
        \draw [fill = black] (2.425, 0.9165) circle [radius = 0.5mm];

        % Host
        \draw (10.0, 1.2497) rectangle (13.0, 3.7493)
                      node[pos = 0.5, align = center] {Host};

        % Verbindungen
        \draw [line width = 1mm] (5, 1.25) -- (6, 1.25) -- (8.499, 3.749) -- (7.499, 3.749);
        \draw [line width = 1mm] (5.833, 2.083) -- (6.833, 2.083);
        \draw [line width = 1mm] (6.666, 2.916) -- (7.666, 2.916);
        \draw [line width = 1mm] (10.0, 2.4995) -- (7.25, 2.4995);

        % Beschriftungen
        \draw (5, 0.25) -- (6.666, -0.3)
                      node[pos = 1.0, align = center, xshift = 6mm] {Device};
        \draw (2.125, 0.25) -- (0.5, -0.75)
                      node[pos = 1.0, align = center, yshift = -2mm] {Compute Unit};
        \draw (0.45, 0.75) -- (-1, 2.35)
                      node[pos = 1.0, align = left, xshift = -6mm] {Processing\\Element};
    \end{tikzpicture}
    \caption{SYCLs Plattform-Modell \cite[nach][23]{opencl2012}}
    \label{sycl:konzepte:abstraktion:plattform}
\end{figure}

Um die Parallelität mehrerer CUs nutzen zu können, ist es sinnvoll, die Arbeit
des Kernels aufzuteilen. Bei acht verfügbaren CUs wäre es daher wünschenswert,
die Berechnungen in mindestens acht Blöcken (oder einem Vielfachen davon)
parallel durchzuführen. Diese Aufteilung wird in \gls{opencl} und SYCL
\textit{work"=group} genannt. \textit{Work"=groups} werden durch ihre Zuordnung
zu unterschiedlichen CUs asynchron zueinander ausgeführt und eine
Synchronisierung der Gruppen ist nicht ohne weiteres möglich.

Eine \textit{work"=group} besteht aus mindestens einem \textit{work"=item},
wobei die Implementierung auch eine maximale Anzahl von \textit{work"=items}
festlegen kann. Ein \textit{work"=item} wird während der Ausführung einem PE
zugeteilt. \textit{Work"=items} werden zueinander asynchron ausgeführt, lassen
sich jedoch über Funktionen der gemeinsamen \textit{work"=group}
synchronisieren. Es ist jedoch nicht möglich, \textit{work"=items} verschiedener
\textit{work"=groups} zu synchronisieren.
% es ist möglich, aber nicht explizit mittels API

Durch diese Hardware"=Abstraktion wird aus Sicht der Programmierers ein
Indexraum aufgespannt -- in OpenCL und SYCL \textit{NDRange} genannt --, in dem
jedem \textit{work"=item} ein eindeutiger Index innerhalb der
\textit{work"=group} sowie der Menge aller \textit{work"=items} zugewiesen wird.
Diese Indizes werden als lokale bzw. globale Indizes bezeichnet. Die
Abbildung~\ref{sycl:konzepte:abstraktion:ndrange} zeigt diese Aufteilung am
Beispiel einer zweidimensionalen \textit{NDRange}. Dabei stehen $G_x$ und 
$G_y$ für die Gesamtzahl der \textit{work"=items} sowie $S_x$ und $S_y$ für die
Zahl der \textit{work"=items} pro \textit{work"=group}, jeweils in x- und
y-Richtung. $w_x$ und $w_y$ bezeichnen die Position der \textit{work"=group}
innerhalb der \textit{NDRange}, während $s_x$ und $s_y$ die Position eines
\textit{work"=items} in der \textit{work"=group} -- also den lokalen Index --
darstellen. Der globale Index $(g_x, g_y)$ eines \textit{work"=items} lässt sich
demnach wie folgt berechnen \cite[vgl.][24]{opencl2012}:
\[
    (g_x, g_y) = (w_x \cdot S_x + s_x, w_y \cdot S_y + s_y)
\]
Die Zahl $(W_x, W_y)$ der \textit{work"=groups} innerhalb der \textit{NDRange}
lässt sich ebenfalls bestimmen \cite[vgl.][25]{opencl2012}:
\[
    (W_x, W_y) = \left(\frac{G_x}{S_x}, \frac{G_y}{S_y}\right)
\]

\begin{figure}
    \centering
    \begin{tikzpicture}
        % NDRange
        \draw (0, 0) rectangle ++(4, 4);

        \draw (0.4, 0.4) rectangle ++(1, 1);
        \draw (0.65, 0.4) -- ++(0, 1);
        \draw (0.9, 0.4) -- ++(0, 1);
        \draw (1.15, 0.4) -- ++(0, 1);
        \draw (0.4, 0.65) -- ++(1, 0);
        \draw (0.4, 0.9) -- ++(1, 0);
        \draw (0.4, 1.15) -- ++(1, 0);

        \draw (1.5, 0.4) rectangle ++(1, 1);
        \draw (1.75, 0.4) -- ++(0, 1);
        \draw (2, 0.4) -- ++(0, 1);
        \draw (2.25, 0.4) -- ++(0, 1);
        \draw (1.5, 0.65) -- ++(1, 0);
        \draw (1.5, 0.9) -- ++(1, 0);
        \draw (1.5, 1.15) -- ++(1, 0);

        \draw (2.6, 0.4) rectangle ++(1, 1);
        \draw (2.85, 0.4) -- ++(0, 1);
        \draw (3.1, 0.4) -- ++(0, 1);
        \draw (3.35, 0.4) -- ++(0, 1);
        \draw (2.6, 0.65) -- ++(1, 0);
        \draw (2.6, 0.9) -- ++(1, 0);
        \draw (2.6, 1.15) -- ++(1, 0);
        
        \draw (0.4, 1.5) rectangle ++(1, 1);
        \draw (0.65, 1.5) -- ++(0, 1);
        \draw (0.9, 1.5) -- ++(0, 1);
        \draw (1.15, 1.5) -- ++(0, 1);
        \draw (0.4, 1.75) -- ++(1, 0);
        \draw (0.4, 2) -- ++(1, 0);
        \draw (0.4, 2.25) -- ++(1, 0);

        \draw (1.5, 1.5) rectangle ++(1, 1);
        \draw (1.75, 1.5) -- ++(0, 1);
        \draw (2, 1.5) -- ++(0, 1);
        \draw (2.25, 1.5) -- ++(0, 1);
        \draw (1.5, 1.75) -- ++(1, 0);
        \draw (1.5, 2) -- ++(1, 0);
        \draw (1.5, 2.25) -- ++(1, 0);

        \draw (2.6, 1.5) rectangle ++(1, 1);
        \draw (2.85, 1.5) -- ++(0, 1);
        \draw (3.1, 1.5) -- ++(0, 1);
        \draw (3.35, 1.5) -- ++(0, 1);
        \draw (2.6, 1.75) -- ++(1, 0);
        \draw (2.6, 2) -- ++(1, 0);
        \draw (2.6, 2.25) -- ++(1, 0);

        \draw (0.4, 2.6) rectangle ++(1, 1);
        \draw (0.65, 2.6) -- ++(0, 1);
        \draw (0.9, 2.6) -- ++(0, 1);
        \draw (1.15, 2.6) -- ++(0, 1);
        \draw (0.4, 2.85) -- ++(1, 0);
        \draw (0.4, 3.1) -- ++(1, 0);
        \draw (0.4, 3.35) -- ++(1, 0);

        \draw (1.5, 2.6) rectangle ++(1, 1);
        \draw (1.75, 2.6) -- ++(0, 1);
        \draw (2, 2.6) -- ++(0, 1);
        \draw (2.25, 2.6) -- ++(0, 1);
        \draw (1.5, 2.85) -- ++(1, 0);
        \draw (1.5, 3.1) -- ++(1, 0);
        \draw (1.5, 3.35) -- ++(1, 0);

        \draw (2.6, 2.6) rectangle ++(1, 1);
        \draw (2.85, 2.6) -- ++(0, 1);
        \draw (3.1, 2.6) -- ++(0, 1);
        \draw (3.35, 2.6) -- ++(0, 1);
        \draw (2.6, 2.85) -- ++(1, 0);
        \draw (2.6, 3.1) -- ++(1, 0);
        \draw (2.6, 3.35) -- ++(1, 0);

        \draw [Latex-Latex] (-0.4, 0) -- ++(0, 4)
            node [pos = 0.5, left] {$G_y$};
        \draw [Latex-Latex] (0, -0.4) -- ++(4, 0)
            node [pos = 0.5, below] {$G_x$};

        % work-group
        \draw [dashed] (1.5, 1.5) -- (5, -0.2);
        \draw [dashed] (2.5, 1.5) -- (13, -0.2);
        \draw [dashed] (1.5, 2.5) -- (5, 8.3);
        \draw [dashed] (2.5, 2.5) -- (13, 8.3);
        \draw [fill = white] (5, -0.2) rectangle ++(8, 8.5);

        \node [align=center] (wgtext) at (9, 7.9) {\textbf{work-group}};

        \draw [Latex-Latex] (5, 8.7) -- ++(8, 0)
            node [pos = 0.5, above] {$S_x$};
        \draw [Latex-Latex] (13.4, -0.2) -- ++(0, 8.5)
            node [pos = 0.5, right] {$S_y$};

        % work-items
        \draw (5.25, 0.05) rectangle ++(3.25, 3.25)
            node [pos = 0.5, align=center] {\textbf{work-item}\\~\\
                                            {\small globaler Index:}\\
                                            ${\scriptstyle (w_x \cdot S_x + s_x, w_y \cdot S_y + s_y)}$\\
                                            {\small lokaler Index:}\\
                                            ${\scriptstyle (s_x, s_y) = (0, S_y - 1)}$};
        \draw (9.5, 0.05) rectangle ++(3.25, 3.25)
            node [pos = 0.5, align=center] {\textbf{work-item}\\~\\
                                            {\small globaler Index:}\\
                                            ${\scriptstyle (w_x \cdot S_x + s_x, w_y \cdot S_y + s_y)}$\\
                                            {\small lokaler Index:}\\
                                            ${\scriptstyle (s_x, s_y) = (S_x - 1, S_y - 1)}$};
        \draw (5.25, 4.3) rectangle ++(3.25, 3.25)
            node [pos = 0.5, align=center] {\textbf{work-item}\\~\\
                                            {\small globaler Index:}\\
                                            ${\scriptstyle (w_x \cdot S_x + s_x, w_y \cdot S_y + s_y)}$\\
                                            {\small lokaler Index:}\\
                                            ${\scriptstyle (s_x, s_y) = (0, 0)}$};
        \draw (9.5, 4.3) rectangle ++(3.25, 3.25)
            node [pos = 0.5, align=center] {\textbf{work-item}\\~\\
                                            {\small globaler Index:}\\
                                            ${\scriptstyle (w_x \cdot S_x + s_x, w_y \cdot S_y + s_y)}$\\
                                            {\small lokaler Index:}\\
                                            ${\scriptstyle (s_x, s_y) = (S_x - 1, 0)}$};

        % Punkte
        \draw [fill = black] (8.8, 1.675) circle [radius = 0.5mm];
        \draw [fill = black] (9, 1.675) circle [radius = 0.5mm];
        \draw [fill = black] (9.2, 1.675) circle [radius = 0.5mm];

        \draw [fill = black] (8.8, 5.925) circle [radius = 0.5mm];
        \draw [fill = black] (9, 5.925) circle [radius = 0.5mm];
        \draw [fill = black] (9.2, 5.925) circle [radius = 0.5mm];

        \draw [fill = black] (6.875, 3.6) circle [radius = 0.5mm];
        \draw [fill = black] (6.875, 3.8) circle [radius = 0.5mm];
        \draw [fill = black] (6.875, 4.0) circle [radius = 0.5mm];

        \draw [fill = black] (11.125, 3.6) circle [radius = 0.5mm];
        \draw [fill = black] (11.125, 3.8) circle [radius = 0.5mm];
        \draw [fill = black] (11.125, 4.0) circle [radius = 0.5mm];

        \draw [fill = black] (8.8, 4.0) circle [radius = 0.5mm];
        \draw [fill = black] (9, 3.8) circle [radius = 0.5mm];
        \draw [fill = black] (9.2, 3.6) circle [radius = 0.5mm];
    \end{tikzpicture}
    \caption{SYCLs Indexraum \cite[nach][25]{opencl2012}}
    \label{sycl:konzepte:abstraktion:ndrange}
\end{figure}

Da eine \textit{NDRange} bis zu drei Dimensionen umfassen kann, lassen sich
mehrdimensionale Algorithmen auf diese Weise einfach implementieren.

Im Unterschied zu \gls{opencl} kann bei SYCL die Angabe der Aufteilung in
\textit{work"=groups} und \textit{work"=items} entfallen, lediglich die
Gesamtzahl der \textit{work"=items} muss angegeben werden. In diesem Fall ist
es Aufgabe der SYCL"=Implementierung, die Zahl der nötigen \textit{work"=groups}
zu bestimmen sowie die Zuordnung der \textit{work"=items} durchzuführen. Dadurch
verliert der Programmierer jedoch die Möglichkeit, gruppenweite Operationen
durchzuführen, wie z.B. die Synchronisierung innerhalb der \textit{work"=group}.
% also generell kein syncthreads in SYCL oder nur wenn work-groups Angabe entfällt?

\subsection{Abhängigkeiten zwischen Kerneln}
\label{sycl:konzepte:abhaengigkeiten}

Alle \textit{command groups}, die der Programmierer in eine
SYCL"=\texttt{queue} einreiht, werden grundsätzlich asynchron ausgeführt, sofern
keine Abhängigkeiten zueinander bestehen. Vorhandene Abhängigkeiten werden über
die von den Kerneln verwendeten Puffer durch die SYCL"=Laufzeitumgebung
automatisch erkannt und die Kernel in der richtigen Reihenfolge ausgeführt
\cite[vgl.][21--23]{sycl2019}. In diesem Aspekt unterscheidet sich SYCL von
\gls{opencl}, das neben vollständig seriellen Warteschlangen nur asynchrone
Warteschlangen kennt, bei denen die richtige Sortierung der Kernel Aufgabe des
Programmierers ist. Wichtig ist außerdem, dass die Abhängigkeiten über die
Puffer"=Verfügbarkeit ermittelt werden -- und nicht über das Ende der Kernel
\cite[vgl.][166]{sycl2019}.

Graphisch lässt sich dies in Form eines gerichteten Graphen veranschaulichen,
wie für einen einfachen Fall in
Abbildung~\ref{sycl:konzepte:abhaengigkeiten:graph} gezeigt. Im Beispiel hängen
die \textit{command groups} B und C von der \textit{command group} A ab, sind
jedoch voneinander unabhängig. Dadurch müssen sie beide auf das Ende von A
warten, können danach jedoch parallel ausgeführt werden. Die
\textit{command group} D benötigt wiederum die in B und C berechneten
Ergebnisse und wartet daher auf deren Ende.

Quelltext~\ref{sycl:konzepte:abhaengigkeiten:src} zeigt die dem Graphen
entsprechende Verwendung einer SYCL"=\texttt{queue}. Wie man leicht sieht, ist
der Aufwand hinsichtlich der Abhängigkeitsverwaltung für den Programmierer sehr
gering.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \draw (0, 0) circle [radius = 5mm] node {A};
        \draw (-1.5, -2.5) circle [radius = 5mm] node {B};
        \draw (1.5, -2.5) circle [radius = 5mm] node {C};
        \draw (0, -5) circle [radius = 5mm] node {D};

        \draw [-Latex] (0, -0.5) -- (-1.5, -2);
        \draw [-Latex] (0, -0.5) -- (1.5, -2);
        \draw [-Latex] (-1.5, -3) -- (0, -4.5);
        \draw [-Latex] (1.5, -3) -- (0, -4.5);
    \end{tikzpicture}
    \caption{Einfacher Aufgabengraph}
    \label{sycl:konzepte:abhaengigkeiten:graph}
\end{figure}

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
queue.submit(/* A */);
queue.submit(/* B */);
queue.submit(/* C */);
queue.submit(/* D */);
    \end{minted}
    \caption{Einfacher SYCL-Aufgabengraph}
    \label{sycl:konzepte:abhaengigkeiten:src}
\end{code}

\subsection{Fehlerbehandlung}

SYCL übernimmt das System der Ausnahmefehler (engl. \textit{exceptions}) aus
der C++"=Standardbibliothek. Das Fehlersystem ist in SYCL asynchron:
grundsätzlich werden nur (synchrone) Fehler der Host"=Seite ausgegeben, während
auf der Device"=Seite aufgetretene Fehler ignoriert werden. Das Abfangen der
Device"=Fehler erfordert einen weiteren Parameter für die \texttt{queue}. Dieser
ist eine Datenstruktur, welche die asynchronen Fehler der Device"=Seite abfängt
und in synchrone Host"=Fehler umwandt, die dann vom Programmierer weiter
verarbeitet werden können (siehe Quelltext~\ref{sycl:konzepte:exceptions:src}).

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
#include <cstdlib>
#include <CL/sycl.hpp>

class XOCLDeviceSelector : public cl::sycl::device_selector {
    /* ... */
};

auto main() -> int
{
    try
    {
        auto exception_handler = [] (cl::sycl::exception_list exceptions)
        {
            for(std::exception_ptr e : exceptions)
            {
                try
                {
                    std::rethrow_exception(e);
                }
                catch(const cl::sycl::exception& err)
                {
                    /* Fehlerbehandlung Device */
                }
            }
        };

        // Beschleunigerwahl und Befehlswarteschlange
        auto queue = cl::sycl::queue{XOCLDeviceSelector{},
                                     exception_handler};

        /* ... */

        // Synchronisierung und Ausnahmefehler
        queue.wait_and_throw();
    }
    catch(const cl::sycl::exception& err)
    {
        /* Fehlerbehandlung Host */
    }

    return EXIT_SUCCESS;
}
    \end{minted}
    \caption{Verwendung von SYCL"=Ausnahmefehlern}
    \label{sycl:konzepte:exceptions:src}
\end{code}

\subsection{Profiling}

SYCL ermöglicht über die \texttt{queue} ein rudimentäres Profiling. Dieses
bietet dem Programmierer die Möglichkeit, über von der \texttt{queue} generierte
\texttt{events} Informationen über Start- und Endzeitpunkt der Kernel sowie den
gegenwärtigen Ausführungsstand eines Kernels zu erhalten. Dazu muss der
\texttt{queue} ein besonderer Parameter während der Konstruktion übergeben
werden (siehe Quelltext~\ref{sycl:konzepte:profiling:src}).

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
#include <cstdlib>
#include <CL/sycl.hpp>

class XOCLDeviceSelector : public cl::sycl::device_selector {
    /* ... */
};

auto main() -> int
{
    // Beschleunigerwahl und Befehlswarteschlange
    auto queue = cl::sycl::queue{XOCLDeviceSelector{},
                                 cl::sycl::property::queue::enable_profiling{}};

    // Kernel-Event generieren
    auto event = queue.submit(/* ... */);

    // Ausführungsstatus abfragen - Rückgabe: submitted, running oder complete
    auto status =
        event.get_info<cl::sycl::info::event::command_execution_status>();

    // Synchronisierung
    queue.wait();

    // Profilinginformationen abfragen - Rückgabe: Zeitpunkt in ns
    auto start =
        event.get_profiling_info<
                            cl::sycl::info::event_profiling::command_start>();
    auto stop =
        event.get_profiling_info<cl::sycl::info::event_profiling::command_end>();

    auto duration = stop - start;

    return EXIT_SUCCESS;
}
    \end{minted}
    \caption{Verwendung von SYCL"=Profiling}
    \label{sycl:konzepte:profiling:src}
\end{code}

\subsection{Referenz-Semantik}

Ein wichtiger Unterschied zur üblichen C++"=Programmierung sind SYCLs
Referenz"=Semantiken. Die Spezifikation schreibt vor
\cite[siehe][Abschnitt 4.3.2]{sycl2019}:
\begin{otherlanguage}{english}
    \begin{quote}
        Each of the following SYCL runtime classes: \texttt{device},
        \texttt{context}, \texttt{queue}, \texttt{program}, \texttt{kernel},
        \texttt{event}, \texttt{buffer}, \texttt{image}, \texttt{sampler},
        \texttt{accessor} and \texttt{stream} must obey the following
        statements, where \texttt{T} is the runtime class: [...]
        \\
        Any instance of \texttt{T} that is constructed as a copy of another
        instance, via either the copy constructor or copy assignment operator,
        must behave as-if it were the original instance and as-if any action
        performed on it were also performed on the original instance and if said
        instance is not a host object must represent and continue to represent
        the same underlying OpenCL objects as the original instance where
        applicable.
    \end{quote}
\end{otherlanguage}
Bemerkenswert ist, dass diese Semantik ebenfalls für die Typen \texttt{buffer}
und \texttt{image} gilt, das heißt Datentypen, die größere Speicherbereiche
kapseln. In der C++-Standardbibliothek werden die internen Felder vergleichbarer
Typen (wie \texttt{vector}) ebenfalls kopiert. Nach dem Kopiervorgang existieren
damit zwei voneinander verschiedene Objekte, die getrennte Speicherbereiche
verwalten. Die SYCL-Objekte beziehen sich jedoch nach dem Kopiervorgang auf den
selben Speicherbereich, es wird also bei der Objektkopie kein neuer Speicher
angelegt. De facto handelt es sich bei der Kopie eines SYCL-Objekts daher
lediglich um eine Referenz auf das ursprüngliche Objekt.

\section{Implementierungen}\label{sycl:implementierungen}

Der ersten Veröffentlichung der SYCL-Spezifikation im Mai 2015 folgten im Laufe
der Zeit einige Implementierungen. Diese werden in den folgenden Abschnitten
vorgestellt.

Darüber hinaus existiert eine von der Firma Codeplay betreute Internet-Seite,
die sich dem gesamten \gls{sycl}"=Ökosystem widmet. \cite[vgl.][]{sycltech}

\subsection{ComputeCpp}

Die schottische Firma Codeplay ist der zur Zeit einzige Anbieter einer
kommerziellen SYCL-Implementierung, die unter dem Namen \textit{ComputeCpp}
vermarktet wird. Sie richtet sich in erster Linie an Hardware für die Bereiche
Automotive und Embedded, unterstützt jedoch (bei einer bereits vorhandenen
OpenCL"=Implementierung) auch \gls{cpu}s und \gls{gpu}s der Firma Intel sowie
(experimentell) NVIDIA-\gls{gpu}s. Nach vorheriger Registrierung ist für
nichtkommerzielle Zwecke auch eine kostenlose \textit{community edition}
verfügbar. \cite[vgl.][]{computecpp}

\subsection{Intel}

Eine wichtige quelloffene Implementierung kommt von der Firma Intel. Strategisch
soll diese Implementierung mit dem Compiler \textit{clang} des LLVM"=Projekts
vereinigt werden. Zur Zeit handelt es sich jedoch noch um eine eigenständige
Implementierung, die vor allem auf die Intel"=\gls{opencl}"=Implementierungen
für \gls{cpu}s und \gls{gpu}s abzielt. Aktivitäten innerhalb des öffentlich
einsehbaren Quelltext"=Repositoriums deuten jedoch darauf hin, dass auch die
eigenen \gls{fpga}s unterstützt werden sollen. \cite[vgl.][]{intelsycl}

\subsection{triSYCL}

Das Projekt triSYCL ist eine quelloffene Implementierung des
\gls{sycl}"=Standards, die früher von der Firma AMD und jetzt von Xilinx
entwickelt wird. Nach eigener Aussage dient es vornehmlich experimentellen
Zwecken, um dem \gls{sycl}"=Komitee und dem \gls{opencl}"=C++"=Komitee des
Khronos"=Konsortiums sowie dem C++"=Standardisierungskomitee der ISO Feedback
liefern zu können. Das Hauptprojekt unterstützt \gls{cpu}s (über \gls{openmp}
oder \gls{tbb}) sowie \gls{opencl}"=Implementierungen, die die Verarbeitung des
\gls{spir}"=Zwischencodes unterstützen. \cite[vgl.][]{trisycl}

Daneben existiert ein von der Intel"=Implementierung abgeleitetes
Compiler-Projekt, das sich vornehmlich der besseren Unterstützung von
Xilinx"=\gls{fpga}s anzunehmen scheint. \cite[vgl.][]{trisyclclang}

\subsection{hipSYCL}

Der Heidelberger Doktorand Aksel Alpay ist der Autor einer weiteren
SYCL-Implementierung. Diese setzt auf dem CUDA"=Klon der Firma AMD auf, der
\gls{gpgpu}"=Sprache \gls{hip}. \gls{hip} ist sowohl auf AMD- als auch auf
NVIDIA"=\gls{gpu}s ausführbar. Dadurch können auch mit hipSYCL entwickelte
Programme auf diesen \gls{gpu}s ausgeführt werden. hipSYCL war über weite
Strecken ein Ein-Mann-Projekt, erst seit Februar 2019 ist die regelmäßige
Mitarbeit eines weiteren Entwicklers zu verzeichnen. Aus diesem Grund ist
hipSYCL unvollständig implementiert, es fehlen unter anderem atomare Funktionen
oder die Möglichkeit, Ausnahmefehler zu werfen und abzufangen.
\cite[vgl.][]{hipsycl}

\subsection{sycl-gtx}

Eine weitere Open-Source-Implementierung ist das eingangs erwähnte
\textit{sycl"=gtx}. Ursprünglich ist diese Implementierung im Rahmen einer
Masterarbeit entstanden \cite[vgl.][]{zuzek2016} und wird bis heute vom
ursprünglichen Autoren weiterentwickelt. Aufgrund der begrenzten
Entwicklerkapazitäten ist diese Variante aber immer noch sehr rudimentär und
unterstützt nur eine Teilmenge der SYCL"=Spezifikation.

Im Gegensatz zu den anderen Implementierungen wird der SYCL"=\gls{kernel} erst
zur Laufzeit des kompilierten Programms in einen \gls{opencl}"=\gls{kernel}
umgewandelt und anschließend an die zugrundeliegende
\gls{opencl}"=Laufzeitumgebung weitergereicht. Dadurch ist \textit{sycl"=gtx}
sehr portabel, da es nicht auf eine bestimmte Hardware beschränkt ist;
grundsätzlich soll es mit jeder \gls{opencl}"=Umgebung kompatibel sein, die
mindestens den Standard in Version 1.2 unterstützt. 
\cite[vgl.][47\psqq]{zuzek2016}

\section{Erweiterungen für FPGAs}\label{sycl:erweiterungen}

Für die \gls{fpga}s des Herstellers Xilinx steht bereits eine experimentelle
\gls{sycl}"=Implementierung zur Verfügung. Um die speziellen Eigenschaften
dieses Hardware"=Typs besser nutzen zu können, gibt es Erweiterungen, die
\gls{sycl}s Funktionsumfang um \gls{fpga}"=spezifische Funktionalität ergänzen.
Diese sind in der Header-Datei \texttt{CL/sycl/xilinx/fpga.hpp} definiert und
werden in den folgenden Abschnitten vorgestellt.

\subsubsection{Datenflussorientierte Ausführung}
\label{sycl:erweiterungen:xilinx:dataflow}

Aus Xilinx' OpenCL-Implementierung übernimmt der triSYCL-Compiler eine
datenflussbasierte Erweiterung. Diese Erweiterung ermöglicht die
aufgabenparallele Ausführung aufeinanderfolgender Funktionen und Schleifen. Mit
ihr wird der Compiler angewiesen, die Abhängigkeiten zwischen den einzelnen
Schritten zu analysieren und für diese Schritte das
\textit{Producer}/\textit{Consumer}-Prinzip durch eine Zwischenschaltung von
Puffern durchzusetzen. \cite[siehe][70\psqq]{sdaccelopt2019}

In OpenCL ist diese Erweiterung als \texttt{xcl\_dataflow} verfügbar und wird
im OpenCL"=C"=Dialekt einem Kernel, einer Funktion oder einer Schleife als
Attribut zugewiesen. Der SYCL"=Implementierung steht diese Erweiterung unter dem
Namen \texttt{dataflow} zur Verfügung. Mit ihr werden Funktionen markiert, auf
deren innere Funktionen und Schleifen die entsprechenden Optimierungen angewandt
werden (siehe Quelltext~\ref{sycl:erweiterungen:xilinx:dataflow:sycl}).

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto body(/* ... */)
{
    /* Funktionskörper */
}

struct kernel
{
    auto operator()()
    {
        cl::sycl::xilinx::dataflow(body(/* ... */));
    }
};
    \end{minted}
    \caption{Datenfluss-Erweiterung in SYCL}
    \label{sycl:erweiterungen:xilinx:dataflow:sycl}
\end{code}

\subsubsection{Pipeline-basierte Ausführung}
\label{sycl:erweiterungen:xilinx:pipeline}

Die triSYCL"=Implementierung übernimmt aus Xilinx' OpenCL-Umgebung eine
pipeline"=basierte Erweiterung. Mit dieser kann der Compiler angewiesen werden,
die Iterationen einer Schleife zu überlappen. Dadurch können die Iterationen
bestimmte Ressourcen zeitgleich nutzen, wodurch sich der Ressourcenverbrauch
insgesamt sowie die Latenz verringern können.
\cite[siehe][67\psqq]{sdaccelopt2019}

In der von Xilinx ausgelieferte OpenCL-Implementierung handelt es sich bei
dieser Erweiterung um das Attribut \texttt{xcl\_pipeline\_loop}, mit dem
Schleifen markiert werden. In SYCL ist sie unter dem Namen \texttt{pipeline}
verfügbar und wird auf Funktionen angewendet, deren innere Schleifen dann dieser
Optimierung unterzogen werden (siehe
Quelltext~\ref{sycl:erweiterungen:xilinx:pipeline:sycl}).

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
auto body(/* ... */)
{
    for(int i = 0; i < 32; ++i)
    {
        /* Schleifenkörper */
    }
}

struct kernel
{
    auto operator()()
    {
        cl::sycl::xilinx::pipeline(body(/* ... */));
    }
};
    \end{minted}
    \caption{Pipeline-Erweiterung in SYCL}
    \label{sycl:erweiterungen:xilinx:pipeline:sycl}
\end{code}

\subsubsection{Feldpartitionierung}
\label{sycl:erweiterungen:xilinx:partitioning}

Durch die Verteilung eines Datenfeldes auf mehrere physische Speichersegmente
lässt sich für manche Anwendungen eine höhere Speicherbandbreite erzielen.
Mit Xilinx' High-Level-Synthese lässt sich ein logisches Datenfeld auf drei
verschiedene Weisen zerlegen: \textit{cyclic}, \textit{block} und
\textit{complete}. \cite[vgl.][16]{sdxpragma2019}

Der Typ \textit{cyclic} führt eine zyklische Zerlegung des Feldes durch. Geht
man von einem acht-elementigen Feld aus und hat vier physische Speicher zur
Verfügung, so werden die Elemente einzeln in aufsteigender Reihenfolge auf die
Speicher aufgeteilt: Element 0 wird dem Speicher 0 zugeordnet, Element 1 dem
Speicher 1, und so weiter. Ist Speicher 3 erreicht, beginnt die Zuteilung wieder
von vorne, Element 4 wird dem Speicher 0 zugeordnet, Element dem Speicher 1,
und so weiter. \cite[vgl.][17]{sdxpragma2019}

Der Typ \textit{block} zerlegt das Feld blockweise. Das heißt, dass zuerst der
Speicher 0 mit den ersten Elementen des Feldes befüllt wird, dann der Speicher
1, und so weiter. \cite[vgl.][17]{sdxpragma2019}

Beim Typ \textit{complete} wird das Feld in einzelne Elemente zerlegt. Dies
entspricht einer Verteilung des Feldes auf einzelne Register.
\cite[vgl.][17]{sdxpragma2019}

Das Attribut \texttt{xcl\_array\_partition(<Typ>, <Faktor>, <Dimension>)} steht
als Erweiterung in Xilinx' OpenCL-Implementierung zur Verfügung, um die
Partitionierung durchzuführen. Dabei bezeichnet \texttt{<Typ>} einen der drei
oben genannten Typen. \cite[vgl.][17]{sdxpragma2019}

\texttt{<Faktor>} gibt für \textit{cyclic} die Anzahl der Speicher an, auf die
das Feld verteilt werden soll, und für \textit{block} die Anzahl der Elemente
pro Speicher. Für den Typ \textit{complete} ist dieser Parameter nicht
definiert. \cite[vgl.][17]{sdxpragma2019}

\texttt{<Dimension>} gibt an, welche Dimension des Feldes auf die beschriebene
Weise partitioniert werden soll. \cite[vgl.][17]{sdxpragma2019}

In SYCL steht diese Erweiterung unter dem Namen \texttt{partition\_array} zur
Verfügung, wobei die Zuweisung der oben aufgeführten Parameter hier über
Templates erfolgt. Der
Quelltext~\ref{sycl:erweiterungen:xilinx:partitioning:sycl} zeigt die Anwendung
dieser Erweiterung.

\begin{code}
    \begin{minted}[fontsize=\small]{c++}
struct kernel
{
    auto operator()()
    {
        // zyklische Verteilung von a auf 4 physische Speicher
        auto a = cl::sycl::xilinx::partition_array<int, 16,
                    cl::sycl::xilinx::partition::cyclic<4, 1>>{};

        // blockweise Verteilung von b mit 4 Elementen pro physischem Speicher
        auto b = cl::sycl::xilinx::partition_array<int, 16,
                    cl::sycl::xilinx::partition::block<4, 1>>{};

        // Zerlegung von c in 16 Register
        auto c = cl::sycl::xilinx::partition_array<int, 16,
                    cl::sycl::xilinx::partition::complete<1>>{};
    }
};
    \end{minted}
    \caption{Feldpartitionierung in SYCL}
    \label{sycl:erweiterungen:xilinx:partitioning:sycl}
\end{code}
