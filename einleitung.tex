\chapter{Einleitung}\label{einleitung}

Die Hardware"=Ausstattungen moderner Computersysteme werden zunehmend heterogen.
Mobiltelefone und PCs verfügen nicht nur über mehrkernige, leistungsstarke
Prozessoren (\gls{cpu}), sondern auch über dedizierte Chips zur
Grafikdarstellung (\gls{gpu}). Währenddessen verschwimmt bei Spielekonsolen und
Laptops die Unterscheidung zwischen Haupt- und Grafikprozessoren dank
integrierter Chips, die beide Funktionalitäten performant abdecken können
(\gls{apu}). Im Bereich des \gls{hpc} sind verschiedene Beschleunigertypen seit
jeher im Einsatz, seien es CPUs mit besonders vielen Kernen, von den GPUs
abstammende Beschleuniger ohne grafische Ausgabe wie NVIDIAs Tesla"=Reihe, oder
Hybride wie Intels kurzlebige Xeon"=Phi"=Produkte.
% Begriff des Beschleunigers verdient Erklärung
% Kapitel 2. heißt FPGAs als Beschleuniger, daher spätestens dort erörtern, ggf. in Hinblick auf Einsatzfelder und Beschleunigerhierarchien

Allen gemeinsam ist die Idee der Beschleunigung eines Algorithmus durch dessen
Parallelisierung, also in der Regel die parallele Ausführung einzelner Schleifeniterationen
auf den in den Beschleunigern vorhandenen Kernen, Multiprozessoren usw. Wie eine
CPU sind die Beschleuniger allerdings darauf ausgelegt, von verschiedenen
Algorithmen genutzt werden zu können, und entsprechend allgemein aufgebaut. Der
Programmierer findet also möglicherweise eine Hardware"=Plattform vor, die für
seinen Algorithmus nicht ideal geeignet ist.

Chips, die für einen speziellen Algorithmus entworfen werden, erfordern durch
die Produktionskosten einen hohen finanziellen Aufwand und sind daher erst ab
hohen Stückzahlen interessant. Darüber hinaus bergen sie das Risiko, geänderten
Einsatzzwecken -- z.B. durch beim Schaltungsentwurf nicht bedachte Aspekte oder
später geänderte Anforderungen -- nicht mehr zu genügen, was wiederum eine
aufwendige Neuentwicklung und -produktion nötig macht. Im schlimmsten Fall ist
der zu tauschende Chip für einen Menschen physisch nicht mehr zu erreichen, wie
etwa in der Raumfahrt.
% ASICs?

Durch dynamisch rekonfigurierbare bzw. programmierbare Hardware lassen sich die
beschriebenen Herausforderungen besser meistern -- wenn auch mit dem Nachteil,
gegenüber spezialisierten Chips deutlich langsamer zu sein. Auf diesem Gebiet
ist vor allem der Hardware"=Typ \gls{fpga} zu nennen. Gegenüber den oben
genannten Beschleunigern und spezialisierten Chips haben FPGAs den Vorteil, dass
die einzelnen Chip"=Bestandteile -- also Logikfunktionen, On"=Chip"=Speicher
usw. -- weitestgehend frei verschaltbar sind. 
Lange Zeit stand dem jedoch die vergleichsweise schwierige Verwendung der
FPGAs entgegen, da diese einen Schaltungsentwurf auf der Register"=Ebene (im
Gegensatz zur Programmierung auf der algorithmischen Ebene) benötigten. Durch
das Aufkommen automatischer Synthese"=Werkzeuge, die Algorithmen in Schaltungen
umwandeln können, wurde der Entwicklungsprozess in jüngerer Zeit
aber deutlich vereinfacht.

Dadurch sind FPGAs auch für Anwendungen abseits des klassischen
Schaltungsentwurfs interessant. Insbesondere latenzkritische Anwendungen können
von FPGAs profitieren, da der Zeitpunkt der Ergebnisausgabe taktgenau
vorhersagbar ist.
% Mit der Vorhersage allein ist es nicht getan. Die FPGAs sind viel flexibler, was die Hardware-Schnittstellen angeht, was wiederum Kommunikationsstrecken zur Peripherie verkürzt.
% Das Hardware-Kompilat des Algorithmus hat idealerweise auch deutlich weniger Overhead auf FPGAs als bei den GPGPU Karten.
% FPGAs sind ggf. auch weniger störanfällig, was sie auch für Teilchenphysikexperimente interessant macht. Sie lassen sich auch besser in Experimentierhardware integrieren als GPUs.
% (Ggf. einen eigenen Absatz für GPUs vs FPGAs aus Anwendersicht)
Die Inferenz neuronaler Netzwerke oder die Verarbeitung großer
Datenströme im \gls{hpc}"=Bereich sind Beispiele für \textit{stream}"=artige
Probleme, die vom Einsatz eines FPGAs profitieren können.
% 2x profitieren

Da die Synthese einer Schaltung je nach Komplexität des Algorithmus einige
Stunden bis Tage benötigen kann, ist für das \textit{Prototyping} ratsam,
schnellere Methoden für die inkrementelle Entwicklung zu wählen -- also z.B.
Beschleuniger. Wünschenswert ist hier vor allem Portabilität zwischen den
verschiedenen Hardware"=Plattformen.

Das ist durchaus nicht unproblematisch: so waren in den Anfangsjahren der
GPU"=Programmierung nur die Produkte des Herstellers NVIDIA ohne Umwege über
Grafikschnittstellen programmierbar, erforderten dafür aber die Nutzung der
NVIDIA"=eigenen CUDA"=Schnittstelle. Diese war (und ist) jedoch nicht mit
Konkurrenzprodukten kompatibel. Für CPUs etablierte sich schnell die
OpenMP"=Schnittstelle als Mittel der Wahl für die Nutzung mehrerer Kerne.
Die Vektorisierung erfordert dagegen entweder befehlssatzspezifische
Erweiterungen, die auch innerhalb derselben Befehlssatzfamilie mitunter
inkompatibel sind, oder sehr gut optimierende Compiler. Die Synthese"=Werkzeuge
der FPGA"=Hersteller ermöglichen zwar die Nutzung der Hochsprachen, reichern
diese aber mit zahlreichen Erweiterungen an, was die Übertragung zwischen den
Plattformen erschwert.
% anfangs ggf. GPGPU Begriff einbringen
% Jahreszahlen?

Um die Entwicklung portabler Programme zu ermöglichen, wurden früh verschiedene
Ansätze entwickelt. Das Khronos"=Industriekonsortium gab wenige Jahre nach der
ersten CUDA"=Veröffentlichung die Spezifikation der OpenCL"=Schnittstelle
heraus.
% Jahresangaben
Dahinter verbarg sich die Idee, eine einheitliche Schnittstelle für den
Programmierer zu schaffen, die im Hintergrund von jedem Hardware"=Hersteller für
die eigenen Produkte implementiert und optimiert wird. Die OpenCL"=Entwicklung
wurde anfangs von zahlreichen namhaften Hard- und Software"=Herstellern
unterstützt (z.B. Apple, AMD, NVIDIA, Intel und Xilinx), flachte jedoch nach
wenigen Jahren wieder ab und konnte sich in der GPU"=Welt nicht gegen CUDA
und auf CPUs nicht gegen OpenMP durchsetzen.

Ein anderer Ansatz liegt in der Entwicklung eines abstrakten Interfaces, das im
Hintergrund auf die herstellereigenen Schnittstellen abgebildet wird. Ein
solches Interface transformiert einen vom Programmierer entwickelten Quelltext
z.B. in einen äquivalenten CUDA"=Quelltext, ohne dass der Programmierer selbst
weitere Anstrengungen in dieser Richtung unternehmen muss. So genügt ein
einfacher Austausch der Zielplattform und eine erneute Kompilierung für die
Nutzung eines anderen Hardware"=Typs. Dieses Prinzip wird von mehreren
parallelen Projekten verfolgt, wie etwa der vom Helmholtz"=Zentrum
Dresden"=Rossendorf entwickelten Alpaka"=Bibliothek oder der Kokkos"=Bibliothek,
die von einer Forschungseinrichtung des US"=amerikanischen Energieministeriums
stammt. Bisher bieten jedoch weder Alpaka noch Kokkos ein Backend für FPGAs an.

Seit einigen Jahren versucht das Khronos"=Konsortium erneut, einen Standard für
die parallele Programmierung zu etablieren. Dieser SYCL genannte Ansatz basiert
auf dem einige Jahre älteren OpenCL, bietet aber eine deutlich modernere und
fortschrittlichere C++"=Programmierschnittstelle. Der neue Standard wird unter
anderem von den FPGA"=Herstellern Xilinx und Intel vorangetrieben und wäre damit
eine interessante Backend"=Variante für die oben genannten
Abstraktionsbibliotheken.

\section{Forschungsstand}\label{einleitung:forschung}

In den letzten Jahren befassten sich mehrere Forschungsgruppen mit der
automatischen \mbox{FPGA}"=Synthese für hochparallele Programme.

Schon 2009 veröffentlichten Papakonstantinou \textit{et al.} einen Ansatz, der
die Synthese einer Schaltung auf Basis der eigentlich für NVIDIA"=GPUs gedachten
CUDA"=Schnittstelle ermöglichte. \cite[vgl.][]{papakonstantinou2009} 

Diese Arbeit konnte sich jedoch nicht langfristig durchsetzen. Seit der ersten
Veröffentlichung einer OpenCL"=Implementierung für FPGAs durch den Hersteller
Altera (heute Intel) im Jahr 2013 verlagerte sich das Interesse der Forschung
auf diese Plattform. 

Eine der ersten Arbeiten in diesem Bereich wurde 2013 von Settle, einem
damaligen Altera"=Mitarbeiter, veröffentlicht. In ihr zeigte Settle den
-- gegenüber der Entwicklung auf Registerebene -- durch eine Hochsprache wie
OpenCL zu erreichenden Produktivitätsgewinn bei gleichzeitiger Beibehaltung der
erreichten Leistung. \cite[vgl.][]{settle2013}

Fifield \textit{et al.} demonstrierten 2016 die Optimierung von
OpenCL"=Programmen für die im Vorjahr veröffentlichte
Xilinx"=OpenCL"=Implementierung. \cite[vgl.][]{fifield2016}

Duarte \textit{et al.} stellten 2018 das \textit{hls4ml}"=Projekt vor. Dabei
handelt es sich um Implementierungen neuronaler Netzwerke, die durch automatische
Synthese in Schaltungen für Xilinx"=FPGAs umgewandelt werden. In diesem Projekt
kommt allerdings nicht OpenCL zum Einsatz, sondern die Xilinx"=Erweiterungen für
die Programmiersprache C++. \cite[vgl.][]{duarte2018}
% überall: neural => neuronal

Die SYCL"=Spezifikation wurde in der Literatur in den ersten Jahren ihres
Bestehens vornehmlich als einfacher Überbau für OpenCL betrachtet. Erst in
jüngerer Zeit kam es zu eigenständigen Untersuchungen SYCLs.

Eine der frühen Arbeiten, die sich von dieser unscharfen Betrachtungsweise
abhebt, ist Žužeks Masterarbeit aus dem Jahre 2016, in deren Rahmen eine
eigenständige \gls{sycl}"=Implementierung entwickelt wurde.
\cite[vgl.][]{zuzek2016}

Wong \textit{et al.}, Mitarbeiter der Firma Codeplay -- einer der führenden
Firmen im SYCL"=Umfeld --, befassten sich ebenfalls 2016 mit den
Wechselwirkungen zwischen dem C++"=Standard und der auf diesem Standard
aufbauenden SYCL"=Spezifikation. Aufmerksamkeit wurde insbesondere den bei der
Codeplay"=SYCL"=Implementierung aufgetretenen Problemen sowie Unzulänglichkeiten
des C++"=Standards zuteil.
\cite[vgl.][]{wong2016}

Aliaga \textit{et al.} veröffentlichten 2017 eine in C++ und SYCL geschriebene
Implementierung der BLAS"=Schnittstelle -- ein Quasistandard für
Rechenoperationen der linearen Algebra --, die sie \textit{SYCL"=BLAS} nannten.
\cite[vgl.][]{aliaga2017}

Burns \textit{et al.} stellten 2019 das \textit{SYCL"=DNN}"=Projekt vor, eine in
C++ und SYCL geschriebene Bibliothek für die Beschleunigung von Operationen, die
typischerweise in neuralen Netzwerken verwendet werden. Teil der Arbeit war auch
ein Vergleich mit den konkurrierenden Bibliotheken cuDNN (NVIDIA) und
MIOpen (AMD). Im Gegensatz zu diesen herstellerspezifischen Bibliotheken soll
SYCL"=DNN auf einer Vielzahl OpenCL"=fähiger Beschleuniger lauffähig sein.
\cite[vgl.][]{burns2019}

Hinsichtlich der Verwendung von SYCL auf FPGAs ist in der Literatur -- neben
einigen untereinander recht ähnlichen Vorträgen des Xilinx"=Mitarbeiters Ronan
Keryell -- bisher nur der 2017 von Doumoulakis \textit{et al.} veröffentlichte
Artikel zu finden, der sich mit der Interoperabilität von SYCL und OpenCL auf
Xilinx"=FPGAs befasst.
\cite[vgl.][]{doumoulakis2017}

Als Backend für Abstraktionsbibliotheken wie Alpaka oder Kokkos fand SYCL bisher
keine Verwendung. Zwar veröffentlichten Copik \textit{et al.} 2017 einen Artikel
über die experimentelle Implementierung eines solchen Backends für die Kokkos
und Alpaka sehr ähnliche Bibliothek \textit{HPX.Compute}, bis heute ist dieser
Entwicklungszweig aber nicht in das Hauptprojekt aufgenommen worden.
\cite[vgl.][]{copik2017}

Im Zusammenhang mit Kokkos findet SYCL bisher nur in Form einer von Hammond
\textit{et al.} 2019 durchgeführten Studie Erwähnung. Dabei handelt es sich
jedoch um einen Vergleich der Programmiermodelle von Kokkos und SYCL und nicht
um eine Implementierung eines Kokkos"=Backends.
\cite[vgl.][]{hammond2019}

\section{Ziel der Arbeit}\label{einleitung:ziel}

In dieser Arbeit wird der SYCL"=Standard hinsichtlich der verfügbaren
Implementierungen und deren Nutzbarkeit untersucht. Dies geschieht vor allem im
Hinblick auf FPGAs, die durch ihre frei veränderbare Hardware"=Konfiguration in
Verbindung mit einer modernen C++"=Programmierschnittstelle eine
vielversprechende Hardware"=Plattform darstellen. Dabei wird ein
experimentelles SYCL"=Backend für die Alpaka-Bibliothek implementiert. Die
während des Entwicklungsprozesses aufgetretenen Schwierigkeiten und
Unzulänglichkeiten werden analysiert, sowie erste Einschätzungen der
Leistungsfähigkeit vorgenommen.
